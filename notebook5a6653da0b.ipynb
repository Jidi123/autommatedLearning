{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf3769b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T05:34:58.354283Z",
     "iopub.status.busy": "2022-04-20T05:34:58.352783Z",
     "iopub.status.idle": "2022-04-20T05:35:09.362719Z",
     "shell.execute_reply": "2022-04-20T05:35:09.361970Z",
     "shell.execute_reply.started": "2022-04-20T05:32:21.681104Z"
    },
    "papermill": {
     "duration": 11.021784,
     "end_time": "2022-04-20T05:35:09.362964",
     "exception": false,
     "start_time": "2022-04-20T05:34:58.341180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipdb\r\n",
      "  Downloading ipdb-0.13.9.tar.gz (16 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from ipdb) (59.5.0)\r\n",
      "Requirement already satisfied: ipython>=7.17.0 in /opt/conda/lib/python3.7/site-packages (from ipdb) (7.30.1)\r\n",
      "Requirement already satisfied: toml>=0.10.2 in /opt/conda/lib/python3.7/site-packages (from ipdb) (0.10.2)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipdb) (5.1.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (0.18.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (0.1.3)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (4.8.0)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (5.1.1)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (0.2.0)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (0.7.5)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (2.10.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=7.17.0->ipdb) (3.0.24)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\r\n",
      "Building wheels for collected packages: ipdb\r\n",
      "  Building wheel for ipdb (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11648 sha256=593bcd7d490d0d7ebf83bcc2ed854c1b3173228d0575aa96b1312295c7747bbb\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/cd/cc/aaf92acae337a28fdd2aa4d632196a59745c8c39f76eaeed01\r\n",
      "Successfully built ipdb\r\n",
      "Installing collected packages: ipdb\r\n",
      "Successfully installed ipdb-0.13.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1356cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T05:35:09.391012Z",
     "iopub.status.busy": "2022-04-20T05:35:09.390252Z",
     "iopub.status.idle": "2022-04-20T05:35:09.393043Z",
     "shell.execute_reply": "2022-04-20T05:35:09.392521Z",
     "shell.execute_reply.started": "2022-04-20T05:31:36.065352Z"
    },
    "papermill": {
     "duration": 0.016769,
     "end_time": "2022-04-20T05:35:09.393150",
     "exception": false,
     "start_time": "2022-04-20T05:35:09.376381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp -r \"/kaggle/input/dfme13/latest_experiments.txt\" /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c08c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T05:35:09.417310Z",
     "iopub.status.busy": "2022-04-20T05:35:09.416555Z",
     "iopub.status.idle": "2022-04-20T05:35:12.786028Z",
     "shell.execute_reply": "2022-04-20T05:35:12.785498Z",
     "shell.execute_reply.started": "2022-04-20T05:33:32.261093Z"
    },
    "papermill": {
     "duration": 3.383161,
     "end_time": "2022-04-20T05:35:12.786160",
     "exception": false,
     "start_time": "2022-04-20T05:35:09.402999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r \"/kaggle/input/project/datafree/dfme/checkpoint/\" /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df5362b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-20T05:35:12.811521Z",
     "iopub.status.busy": "2022-04-20T05:35:12.810711Z",
     "iopub.status.idle": "2022-04-20T05:35:12.813157Z",
     "shell.execute_reply": "2022-04-20T05:35:12.812730Z",
     "shell.execute_reply.started": "2022-04-20T05:31:36.087278Z"
    },
    "papermill": {
     "duration": 0.016605,
     "end_time": "2022-04-20T05:35:12.813279",
     "exception": false,
     "start_time": "2022-04-20T05:35:12.796674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf \"/kaggle/output/checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a13118e",
   "metadata": {
    "_cell_guid": "da78b23e-5235-488a-8425-af2f25c94025",
    "_uuid": "18b534c0-0ef1-4b1d-9f22-7b767e01c712",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-04-20T05:35:12.852528Z",
     "iopub.status.busy": "2022-04-20T05:35:12.842399Z",
     "iopub.status.idle": "2022-04-20T11:39:17.158662Z",
     "shell.execute_reply": "2022-04-20T11:39:17.158103Z",
     "shell.execute_reply.started": "2022-04-20T05:32:35.609256Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 21844.335346,
     "end_time": "2022-04-20T11:39:17.158833",
     "exception": false,
     "start_time": "2022-04-20T05:35:12.823487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version 1.9.1\n",
      "Namespace(MAZE=0, approx_grad=1, batch_size=256, ckpt='/kaggle/working/checkpoint/teacher/cifar10-resnet34_8x.pt', d_iter=5, data_root='/kaggle/working/data', dataset='cifar10', device=0, epoch_itrs=50, forward_differences=1, g_iter=1, grad_epsilon=0.001, grad_m=1, log_dir='/kaggle/working/save_results/cifar10', log_interval=10, logit_correction='mean', loss='l1', lr_G=0.0001, lr_S=0.1, model='resnet34_8x', model_id='debug', momentum=0.9, no_cuda=False, no_logits=1, nz=256, query_budget=20000000, rec_grad_norm=1, scale=0.3, scheduler='multistep', seed=10990, steps=[0.1, 0.3, 0.5], store_checkpoints=1, student_load_path=None, student_model='resnet18_8x', weight_decay=0.0005)\n",
      "/kaggle/working/save_results/cifar10\n",
      "Namespace(MAZE=0, approx_grad=1, batch_size=256, ckpt='/kaggle/working/checkpoint/teacher/cifar10-resnet34_8x.pt', d_iter=5, data_root='/kaggle/working/data', dataset='cifar10', device=0, epoch_itrs=50, forward_differences=1, g_iter=1, grad_epsilon=0.001, grad_m=1, log_dir='/kaggle/working/save_results/cifar10', log_interval=10, logit_correction='mean', loss='l1', lr_G=0.0001, lr_S=0.1, model='resnet34_8x', model_dir='/kaggle/working/checkpoint/student_debug', model_id='debug', momentum=0.9, no_cuda=False, no_logits=1, nz=256, query_budget=20000000, rec_grad_norm=1, scale=0.3, scheduler='multistep', seed=10990, steps=[0.1, 0.3, 0.5], store_checkpoints=1, student_load_path=None, student_model='resnet18_8x', weight_decay=0.0005)\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /kaggle/working/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c793af3c27ad487d89a39789866c5ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /kaggle/working/data/cifar-10-python.tar.gz to /kaggle/working/data\n",
      "Files already downloaded and verified\n",
      "Teacher restored from /kaggle/working/checkpoint/teacher/cifar10-resnet34_8x.pt\n",
      "\n",
      "\t\tTraining with resnet34_8x as a Target\n",
      "\n",
      "\n",
      "Teacher - Test set: Accuracy: 9554/10000 (95.5400%)\n",
      "\n",
      "\n",
      "Total budget: 20000k\n",
      "Cost per iterations:  1792\n",
      "Total number of epochs:  224\n",
      "Learning rate scheduling at steps:  [22, 67, 112]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50 (0%)]\tG_Loss: -2.108850 S_loss: 1.376181\n",
      "Train Epoch: 1 [10/50 (20%)]\tG_Loss: -0.953709 S_loss: 0.846798\n",
      "Train Epoch: 1 [20/50 (40%)]\tG_Loss: -0.848292 S_loss: 0.866706\n",
      "Train Epoch: 1 [30/50 (60%)]\tG_Loss: -0.852366 S_loss: 0.884151\n",
      "Train Epoch: 1 [40/50 (80%)]\tG_Loss: -0.828690 S_loss: 0.846035\n",
      "\n",
      "Test set: Average loss: 7.0375, Accuracy: 1036/10000 (10.3600%)\n",
      "\n",
      "Train Epoch: 2 [0/50 (0%)]\tG_Loss: -0.840765 S_loss: 0.905674\n",
      "Train Epoch: 2 [10/50 (20%)]\tG_Loss: -0.849933 S_loss: 0.887290\n",
      "Train Epoch: 2 [20/50 (40%)]\tG_Loss: -0.892443 S_loss: 0.896033\n",
      "Train Epoch: 2 [30/50 (60%)]\tG_Loss: -0.903009 S_loss: 0.902849\n",
      "Train Epoch: 2 [40/50 (80%)]\tG_Loss: -0.886303 S_loss: 0.887133\n",
      "\n",
      "Test set: Average loss: 5.2132, Accuracy: 1033/10000 (10.3300%)\n",
      "\n",
      "Train Epoch: 3 [0/50 (0%)]\tG_Loss: -0.959613 S_loss: 0.903424\n",
      "Train Epoch: 3 [10/50 (20%)]\tG_Loss: -0.938126 S_loss: 0.901380\n",
      "Train Epoch: 3 [20/50 (40%)]\tG_Loss: -0.926078 S_loss: 0.866620\n",
      "Train Epoch: 3 [30/50 (60%)]\tG_Loss: -0.966235 S_loss: 0.928279\n",
      "Train Epoch: 3 [40/50 (80%)]\tG_Loss: -0.863705 S_loss: 0.884479\n",
      "\n",
      "Test set: Average loss: 4.0837, Accuracy: 1859/10000 (18.5900%)\n",
      "\n",
      "Train Epoch: 4 [0/50 (0%)]\tG_Loss: -0.922924 S_loss: 0.862885\n",
      "Train Epoch: 4 [10/50 (20%)]\tG_Loss: -0.905282 S_loss: 0.892593\n",
      "Train Epoch: 4 [20/50 (40%)]\tG_Loss: -0.925363 S_loss: 0.898896\n",
      "Train Epoch: 4 [30/50 (60%)]\tG_Loss: -0.876939 S_loss: 0.908964\n",
      "Train Epoch: 4 [40/50 (80%)]\tG_Loss: -1.010032 S_loss: 0.885879\n",
      "\n",
      "Test set: Average loss: 4.7011, Accuracy: 1596/10000 (15.9600%)\n",
      "\n",
      "Train Epoch: 5 [0/50 (0%)]\tG_Loss: -1.054021 S_loss: 0.876861\n",
      "Train Epoch: 5 [10/50 (20%)]\tG_Loss: -0.933991 S_loss: 0.853531\n",
      "Train Epoch: 5 [20/50 (40%)]\tG_Loss: -0.912347 S_loss: 0.891451\n",
      "Train Epoch: 5 [30/50 (60%)]\tG_Loss: -0.960184 S_loss: 0.870375\n",
      "Train Epoch: 5 [40/50 (80%)]\tG_Loss: -0.964203 S_loss: 0.852887\n",
      "\n",
      "Test set: Average loss: 4.3776, Accuracy: 2241/10000 (22.4100%)\n",
      "\n",
      "Train Epoch: 6 [0/50 (0%)]\tG_Loss: -1.102602 S_loss: 0.875323\n",
      "Train Epoch: 6 [10/50 (20%)]\tG_Loss: -0.919009 S_loss: 0.886819\n",
      "Train Epoch: 6 [20/50 (40%)]\tG_Loss: -1.041237 S_loss: 0.879540\n",
      "Train Epoch: 6 [30/50 (60%)]\tG_Loss: -1.161368 S_loss: 0.903696\n",
      "Train Epoch: 6 [40/50 (80%)]\tG_Loss: -0.996208 S_loss: 0.885335\n",
      "\n",
      "Test set: Average loss: 3.9565, Accuracy: 2923/10000 (29.2300%)\n",
      "\n",
      "Train Epoch: 7 [0/50 (0%)]\tG_Loss: -0.890737 S_loss: 0.874294\n",
      "Train Epoch: 7 [10/50 (20%)]\tG_Loss: -1.042981 S_loss: 0.858302\n",
      "Train Epoch: 7 [20/50 (40%)]\tG_Loss: -0.915158 S_loss: 0.860389\n",
      "Train Epoch: 7 [30/50 (60%)]\tG_Loss: -1.072947 S_loss: 0.871129\n",
      "Train Epoch: 7 [40/50 (80%)]\tG_Loss: -1.227945 S_loss: 0.874323\n",
      "\n",
      "Test set: Average loss: 4.1833, Accuracy: 2889/10000 (28.8900%)\n",
      "\n",
      "Train Epoch: 8 [0/50 (0%)]\tG_Loss: -1.259051 S_loss: 0.829700\n",
      "Train Epoch: 8 [10/50 (20%)]\tG_Loss: -1.243443 S_loss: 0.812259\n",
      "Train Epoch: 8 [20/50 (40%)]\tG_Loss: -0.911862 S_loss: 0.828448\n",
      "Train Epoch: 8 [30/50 (60%)]\tG_Loss: -0.887360 S_loss: 0.834483\n",
      "Train Epoch: 8 [40/50 (80%)]\tG_Loss: -0.888726 S_loss: 0.844059\n",
      "\n",
      "Test set: Average loss: 5.0009, Accuracy: 2946/10000 (29.4600%)\n",
      "\n",
      "Train Epoch: 9 [0/50 (0%)]\tG_Loss: -0.962766 S_loss: 0.834560\n",
      "Train Epoch: 9 [10/50 (20%)]\tG_Loss: -1.131202 S_loss: 0.849850\n",
      "Train Epoch: 9 [20/50 (40%)]\tG_Loss: -0.894790 S_loss: 0.818726\n",
      "Train Epoch: 9 [30/50 (60%)]\tG_Loss: -1.029973 S_loss: 0.822974\n",
      "Train Epoch: 9 [40/50 (80%)]\tG_Loss: -1.178708 S_loss: 0.784925\n",
      "\n",
      "Test set: Average loss: 5.6761, Accuracy: 2863/10000 (28.6300%)\n",
      "\n",
      "Train Epoch: 10 [0/50 (0%)]\tG_Loss: -1.203030 S_loss: 0.824311\n",
      "Train Epoch: 10 [10/50 (20%)]\tG_Loss: -0.959503 S_loss: 0.797900\n",
      "Train Epoch: 10 [20/50 (40%)]\tG_Loss: -1.092292 S_loss: 0.826691\n",
      "Train Epoch: 10 [30/50 (60%)]\tG_Loss: -0.914759 S_loss: 0.803355\n",
      "Train Epoch: 10 [40/50 (80%)]\tG_Loss: -1.232702 S_loss: 0.798050\n",
      "\n",
      "Test set: Average loss: 4.4914, Accuracy: 3569/10000 (35.6900%)\n",
      "\n",
      "Train Epoch: 11 [0/50 (0%)]\tG_Loss: -0.995556 S_loss: 0.790531\n",
      "Train Epoch: 11 [10/50 (20%)]\tG_Loss: -0.873367 S_loss: 0.786148\n",
      "Train Epoch: 11 [20/50 (40%)]\tG_Loss: -0.865730 S_loss: 0.759716\n",
      "Train Epoch: 11 [30/50 (60%)]\tG_Loss: -1.103929 S_loss: 0.786512\n",
      "Train Epoch: 11 [40/50 (80%)]\tG_Loss: -0.894226 S_loss: 0.770199\n",
      "\n",
      "Test set: Average loss: 4.4437, Accuracy: 3588/10000 (35.8800%)\n",
      "\n",
      "Train Epoch: 12 [0/50 (0%)]\tG_Loss: -0.917517 S_loss: 0.746849\n",
      "Train Epoch: 12 [10/50 (20%)]\tG_Loss: -1.016323 S_loss: 0.775554\n",
      "Train Epoch: 12 [20/50 (40%)]\tG_Loss: -0.914250 S_loss: 0.754879\n",
      "Train Epoch: 12 [30/50 (60%)]\tG_Loss: -0.798661 S_loss: 0.785038\n",
      "Train Epoch: 12 [40/50 (80%)]\tG_Loss: -0.784441 S_loss: 0.762090\n",
      "\n",
      "Test set: Average loss: 3.2633, Accuracy: 4055/10000 (40.5500%)\n",
      "\n",
      "Train Epoch: 13 [0/50 (0%)]\tG_Loss: -1.059182 S_loss: 0.761605\n",
      "Train Epoch: 13 [10/50 (20%)]\tG_Loss: -0.887668 S_loss: 0.773913\n",
      "Train Epoch: 13 [20/50 (40%)]\tG_Loss: -0.838545 S_loss: 0.754121\n",
      "Train Epoch: 13 [30/50 (60%)]\tG_Loss: -1.098962 S_loss: 0.748511\n",
      "Train Epoch: 13 [40/50 (80%)]\tG_Loss: -1.038622 S_loss: 0.743829\n",
      "\n",
      "Test set: Average loss: 3.1119, Accuracy: 4392/10000 (43.9200%)\n",
      "\n",
      "Train Epoch: 14 [0/50 (0%)]\tG_Loss: -0.865487 S_loss: 0.750271\n",
      "Train Epoch: 14 [10/50 (20%)]\tG_Loss: -0.855813 S_loss: 0.739736\n",
      "Train Epoch: 14 [20/50 (40%)]\tG_Loss: -0.863579 S_loss: 0.740981\n",
      "Train Epoch: 14 [30/50 (60%)]\tG_Loss: -0.851819 S_loss: 0.737209\n",
      "Train Epoch: 14 [40/50 (80%)]\tG_Loss: -0.854411 S_loss: 0.763086\n",
      "\n",
      "Test set: Average loss: 3.1360, Accuracy: 4470/10000 (44.7000%)\n",
      "\n",
      "Train Epoch: 15 [0/50 (0%)]\tG_Loss: -1.094633 S_loss: 0.747685\n",
      "Train Epoch: 15 [10/50 (20%)]\tG_Loss: -1.180349 S_loss: 0.722787\n",
      "Train Epoch: 15 [20/50 (40%)]\tG_Loss: -0.819494 S_loss: 0.721684\n",
      "Train Epoch: 15 [30/50 (60%)]\tG_Loss: -0.945091 S_loss: 0.730667\n",
      "Train Epoch: 15 [40/50 (80%)]\tG_Loss: -0.898569 S_loss: 0.711886\n",
      "\n",
      "Test set: Average loss: 3.2392, Accuracy: 4615/10000 (46.1500%)\n",
      "\n",
      "Train Epoch: 16 [0/50 (0%)]\tG_Loss: -0.835878 S_loss: 0.739091\n",
      "Train Epoch: 16 [10/50 (20%)]\tG_Loss: -0.830765 S_loss: 0.728929\n",
      "Train Epoch: 16 [20/50 (40%)]\tG_Loss: -0.981133 S_loss: 0.714781\n",
      "Train Epoch: 16 [30/50 (60%)]\tG_Loss: -1.030509 S_loss: 0.747785\n",
      "Train Epoch: 16 [40/50 (80%)]\tG_Loss: -0.927558 S_loss: 0.723877\n",
      "\n",
      "Test set: Average loss: 2.3720, Accuracy: 5341/10000 (53.4100%)\n",
      "\n",
      "Train Epoch: 17 [0/50 (0%)]\tG_Loss: -0.999459 S_loss: 0.741457\n",
      "Train Epoch: 17 [10/50 (20%)]\tG_Loss: -0.931747 S_loss: 0.724187\n",
      "Train Epoch: 17 [20/50 (40%)]\tG_Loss: -0.955619 S_loss: 0.718163\n",
      "Train Epoch: 17 [30/50 (60%)]\tG_Loss: -1.025182 S_loss: 0.713253\n",
      "Train Epoch: 17 [40/50 (80%)]\tG_Loss: -0.831918 S_loss: 0.714000\n",
      "\n",
      "Test set: Average loss: 2.5399, Accuracy: 5147/10000 (51.4700%)\n",
      "\n",
      "Train Epoch: 18 [0/50 (0%)]\tG_Loss: -0.833061 S_loss: 0.717844\n",
      "Train Epoch: 18 [10/50 (20%)]\tG_Loss: -0.902102 S_loss: 0.716642\n",
      "Train Epoch: 18 [20/50 (40%)]\tG_Loss: -0.871905 S_loss: 0.728407\n",
      "Train Epoch: 18 [30/50 (60%)]\tG_Loss: -0.835946 S_loss: 0.717941\n",
      "Train Epoch: 18 [40/50 (80%)]\tG_Loss: -0.887049 S_loss: 0.699648\n",
      "\n",
      "Test set: Average loss: 3.8185, Accuracy: 4091/10000 (40.9100%)\n",
      "\n",
      "Train Epoch: 19 [0/50 (0%)]\tG_Loss: -0.878249 S_loss: 0.699531\n",
      "Train Epoch: 19 [10/50 (20%)]\tG_Loss: -0.893260 S_loss: 0.717468\n",
      "Train Epoch: 19 [20/50 (40%)]\tG_Loss: -1.028731 S_loss: 0.686303\n",
      "Train Epoch: 19 [30/50 (60%)]\tG_Loss: -0.827904 S_loss: 0.686636\n",
      "Train Epoch: 19 [40/50 (80%)]\tG_Loss: -0.824443 S_loss: 0.714653\n",
      "\n",
      "Test set: Average loss: 2.7353, Accuracy: 4957/10000 (49.5700%)\n",
      "\n",
      "Train Epoch: 20 [0/50 (0%)]\tG_Loss: -0.861309 S_loss: 0.693404\n",
      "Train Epoch: 20 [10/50 (20%)]\tG_Loss: -0.829273 S_loss: 0.694973\n",
      "Train Epoch: 20 [20/50 (40%)]\tG_Loss: -0.890045 S_loss: 0.703759\n",
      "Train Epoch: 20 [30/50 (60%)]\tG_Loss: -0.951392 S_loss: 0.688845\n",
      "Train Epoch: 20 [40/50 (80%)]\tG_Loss: -0.797901 S_loss: 0.672836\n",
      "\n",
      "Test set: Average loss: 2.2495, Accuracy: 5407/10000 (54.0700%)\n",
      "\n",
      "Train Epoch: 21 [0/50 (0%)]\tG_Loss: -0.818354 S_loss: 0.694814\n",
      "Train Epoch: 21 [10/50 (20%)]\tG_Loss: -1.515515 S_loss: 0.711254\n",
      "Train Epoch: 21 [20/50 (40%)]\tG_Loss: -1.273835 S_loss: 0.699712\n",
      "Train Epoch: 21 [30/50 (60%)]\tG_Loss: -1.101948 S_loss: 0.695969\n",
      "Train Epoch: 21 [40/50 (80%)]\tG_Loss: -0.831325 S_loss: 0.716424\n",
      "\n",
      "Test set: Average loss: 2.6731, Accuracy: 5010/10000 (50.1000%)\n",
      "\n",
      "Train Epoch: 22 [0/50 (0%)]\tG_Loss: -1.157668 S_loss: 0.689784\n",
      "Train Epoch: 22 [10/50 (20%)]\tG_Loss: -0.665682 S_loss: 0.643368\n",
      "Train Epoch: 22 [20/50 (40%)]\tG_Loss: -0.644628 S_loss: 0.614401\n",
      "Train Epoch: 22 [30/50 (60%)]\tG_Loss: -0.641814 S_loss: 0.632148\n",
      "Train Epoch: 22 [40/50 (80%)]\tG_Loss: -0.622499 S_loss: 0.614079\n",
      "\n",
      "Test set: Average loss: 1.8947, Accuracy: 6053/10000 (60.5300%)\n",
      "\n",
      "Train Epoch: 23 [0/50 (0%)]\tG_Loss: -0.625699 S_loss: 0.616346\n",
      "Train Epoch: 23 [10/50 (20%)]\tG_Loss: -0.634616 S_loss: 0.592281\n",
      "Train Epoch: 23 [20/50 (40%)]\tG_Loss: -0.644863 S_loss: 0.605752\n",
      "Train Epoch: 23 [30/50 (60%)]\tG_Loss: -0.647986 S_loss: 0.607948\n",
      "Train Epoch: 23 [40/50 (80%)]\tG_Loss: -0.638736 S_loss: 0.615653\n",
      "\n",
      "Test set: Average loss: 2.1912, Accuracy: 5772/10000 (57.7200%)\n",
      "\n",
      "Train Epoch: 24 [0/50 (0%)]\tG_Loss: -0.742230 S_loss: 0.575046\n",
      "Train Epoch: 24 [10/50 (20%)]\tG_Loss: -0.659868 S_loss: 0.627437\n",
      "Train Epoch: 24 [20/50 (40%)]\tG_Loss: -0.616139 S_loss: 0.601431\n",
      "Train Epoch: 24 [30/50 (60%)]\tG_Loss: -0.659534 S_loss: 0.605298\n",
      "Train Epoch: 24 [40/50 (80%)]\tG_Loss: -0.621520 S_loss: 0.598141\n",
      "\n",
      "Test set: Average loss: 1.8719, Accuracy: 6263/10000 (62.6300%)\n",
      "\n",
      "Train Epoch: 25 [0/50 (0%)]\tG_Loss: -0.653180 S_loss: 0.584264\n",
      "Train Epoch: 25 [10/50 (20%)]\tG_Loss: -0.675929 S_loss: 0.584856\n",
      "Train Epoch: 25 [20/50 (40%)]\tG_Loss: -0.647123 S_loss: 0.583156\n",
      "Train Epoch: 25 [30/50 (60%)]\tG_Loss: -0.596630 S_loss: 0.585075\n",
      "Train Epoch: 25 [40/50 (80%)]\tG_Loss: -0.655979 S_loss: 0.598064\n",
      "\n",
      "Test set: Average loss: 1.8307, Accuracy: 6290/10000 (62.9000%)\n",
      "\n",
      "Train Epoch: 26 [0/50 (0%)]\tG_Loss: -0.639008 S_loss: 0.581695\n",
      "Train Epoch: 26 [10/50 (20%)]\tG_Loss: -0.746606 S_loss: 0.590370\n",
      "Train Epoch: 26 [20/50 (40%)]\tG_Loss: -0.636556 S_loss: 0.598689\n",
      "Train Epoch: 26 [30/50 (60%)]\tG_Loss: -0.606288 S_loss: 0.613671\n",
      "Train Epoch: 26 [40/50 (80%)]\tG_Loss: -0.666242 S_loss: 0.602218\n",
      "\n",
      "Test set: Average loss: 1.4991, Accuracy: 6745/10000 (67.4500%)\n",
      "\n",
      "Train Epoch: 27 [0/50 (0%)]\tG_Loss: -0.615514 S_loss: 0.584440\n",
      "Train Epoch: 27 [10/50 (20%)]\tG_Loss: -0.646257 S_loss: 0.614599\n",
      "Train Epoch: 27 [20/50 (40%)]\tG_Loss: -0.614418 S_loss: 0.594010\n",
      "Train Epoch: 27 [30/50 (60%)]\tG_Loss: -0.675312 S_loss: 0.601555\n",
      "Train Epoch: 27 [40/50 (80%)]\tG_Loss: -0.708533 S_loss: 0.589949\n",
      "\n",
      "Test set: Average loss: 1.7873, Accuracy: 6352/10000 (63.5200%)\n",
      "\n",
      "Train Epoch: 28 [0/50 (0%)]\tG_Loss: -0.736293 S_loss: 0.607135\n",
      "Train Epoch: 28 [10/50 (20%)]\tG_Loss: -0.602178 S_loss: 0.606403\n",
      "Train Epoch: 28 [20/50 (40%)]\tG_Loss: -0.630315 S_loss: 0.592003\n",
      "Train Epoch: 28 [30/50 (60%)]\tG_Loss: -0.622490 S_loss: 0.607246\n",
      "Train Epoch: 28 [40/50 (80%)]\tG_Loss: -0.625324 S_loss: 0.584718\n",
      "\n",
      "Test set: Average loss: 1.7754, Accuracy: 6322/10000 (63.2200%)\n",
      "\n",
      "Train Epoch: 29 [0/50 (0%)]\tG_Loss: -0.740589 S_loss: 0.586436\n",
      "Train Epoch: 29 [10/50 (20%)]\tG_Loss: -0.676994 S_loss: 0.594660\n",
      "Train Epoch: 29 [20/50 (40%)]\tG_Loss: -0.626737 S_loss: 0.592735\n",
      "Train Epoch: 29 [30/50 (60%)]\tG_Loss: -0.636826 S_loss: 0.591854\n",
      "Train Epoch: 29 [40/50 (80%)]\tG_Loss: -0.778108 S_loss: 0.576333\n",
      "\n",
      "Test set: Average loss: 1.7167, Accuracy: 6357/10000 (63.5700%)\n",
      "\n",
      "Train Epoch: 30 [0/50 (0%)]\tG_Loss: -0.687838 S_loss: 0.590352\n",
      "Train Epoch: 30 [10/50 (20%)]\tG_Loss: -0.692162 S_loss: 0.618492\n",
      "Train Epoch: 30 [20/50 (40%)]\tG_Loss: -0.658789 S_loss: 0.600891\n",
      "Train Epoch: 30 [30/50 (60%)]\tG_Loss: -0.623733 S_loss: 0.598630\n",
      "Train Epoch: 30 [40/50 (80%)]\tG_Loss: -0.630909 S_loss: 0.602083\n",
      "\n",
      "Test set: Average loss: 1.8360, Accuracy: 6404/10000 (64.0400%)\n",
      "\n",
      "Train Epoch: 31 [0/50 (0%)]\tG_Loss: -0.773742 S_loss: 0.597173\n",
      "Train Epoch: 31 [10/50 (20%)]\tG_Loss: -0.655570 S_loss: 0.604559\n",
      "Train Epoch: 31 [20/50 (40%)]\tG_Loss: -0.627203 S_loss: 0.599312\n",
      "Train Epoch: 31 [30/50 (60%)]\tG_Loss: -0.736731 S_loss: 0.556246\n",
      "Train Epoch: 31 [40/50 (80%)]\tG_Loss: -0.659040 S_loss: 0.601565\n",
      "\n",
      "Test set: Average loss: 1.4853, Accuracy: 6641/10000 (66.4100%)\n",
      "\n",
      "Train Epoch: 32 [0/50 (0%)]\tG_Loss: -0.614545 S_loss: 0.588338\n",
      "Train Epoch: 32 [10/50 (20%)]\tG_Loss: -0.680458 S_loss: 0.588413\n",
      "Train Epoch: 32 [20/50 (40%)]\tG_Loss: -0.660542 S_loss: 0.572913\n",
      "Train Epoch: 32 [30/50 (60%)]\tG_Loss: -0.628195 S_loss: 0.586427\n",
      "Train Epoch: 32 [40/50 (80%)]\tG_Loss: -0.617741 S_loss: 0.586147\n",
      "\n",
      "Test set: Average loss: 1.6694, Accuracy: 6556/10000 (65.5600%)\n",
      "\n",
      "Train Epoch: 33 [0/50 (0%)]\tG_Loss: -0.643139 S_loss: 0.582990\n",
      "Train Epoch: 33 [10/50 (20%)]\tG_Loss: -0.667070 S_loss: 0.599723\n",
      "Train Epoch: 33 [20/50 (40%)]\tG_Loss: -0.622936 S_loss: 0.610815\n",
      "Train Epoch: 33 [30/50 (60%)]\tG_Loss: -0.625095 S_loss: 0.555192\n",
      "Train Epoch: 33 [40/50 (80%)]\tG_Loss: -0.621826 S_loss: 0.580510\n",
      "\n",
      "Test set: Average loss: 1.3403, Accuracy: 6907/10000 (69.0700%)\n",
      "\n",
      "Train Epoch: 34 [0/50 (0%)]\tG_Loss: -0.661578 S_loss: 0.600556\n",
      "Train Epoch: 34 [10/50 (20%)]\tG_Loss: -0.663470 S_loss: 0.604870\n",
      "Train Epoch: 34 [20/50 (40%)]\tG_Loss: -0.623884 S_loss: 0.596808\n",
      "Train Epoch: 34 [30/50 (60%)]\tG_Loss: -0.684686 S_loss: 0.570642\n",
      "Train Epoch: 34 [40/50 (80%)]\tG_Loss: -0.663166 S_loss: 0.575417\n",
      "\n",
      "Test set: Average loss: 1.5871, Accuracy: 6560/10000 (65.6000%)\n",
      "\n",
      "Train Epoch: 35 [0/50 (0%)]\tG_Loss: -0.651998 S_loss: 0.576285\n",
      "Train Epoch: 35 [10/50 (20%)]\tG_Loss: -0.640447 S_loss: 0.574682\n",
      "Train Epoch: 35 [20/50 (40%)]\tG_Loss: -0.698108 S_loss: 0.560030\n",
      "Train Epoch: 35 [30/50 (60%)]\tG_Loss: -0.640503 S_loss: 0.588860\n",
      "Train Epoch: 35 [40/50 (80%)]\tG_Loss: -0.736932 S_loss: 0.595194\n",
      "\n",
      "Test set: Average loss: 1.7981, Accuracy: 6474/10000 (64.7400%)\n",
      "\n",
      "Train Epoch: 36 [0/50 (0%)]\tG_Loss: -0.612487 S_loss: 0.594472\n",
      "Train Epoch: 36 [10/50 (20%)]\tG_Loss: -0.655049 S_loss: 0.577185\n",
      "Train Epoch: 36 [20/50 (40%)]\tG_Loss: -0.603643 S_loss: 0.573291\n",
      "Train Epoch: 36 [30/50 (60%)]\tG_Loss: -0.720750 S_loss: 0.554685\n",
      "Train Epoch: 36 [40/50 (80%)]\tG_Loss: -0.617330 S_loss: 0.577501\n",
      "\n",
      "Test set: Average loss: 1.4438, Accuracy: 6789/10000 (67.8900%)\n",
      "\n",
      "Train Epoch: 37 [0/50 (0%)]\tG_Loss: -0.612579 S_loss: 0.586462\n",
      "Train Epoch: 37 [10/50 (20%)]\tG_Loss: -0.622723 S_loss: 0.577087\n",
      "Train Epoch: 37 [20/50 (40%)]\tG_Loss: -0.644865 S_loss: 0.577699\n",
      "Train Epoch: 37 [30/50 (60%)]\tG_Loss: -0.639572 S_loss: 0.576975\n",
      "Train Epoch: 37 [40/50 (80%)]\tG_Loss: -0.621741 S_loss: 0.611350\n",
      "\n",
      "Test set: Average loss: 1.3584, Accuracy: 6816/10000 (68.1600%)\n",
      "\n",
      "Train Epoch: 38 [0/50 (0%)]\tG_Loss: -0.609155 S_loss: 0.580029\n",
      "Train Epoch: 38 [10/50 (20%)]\tG_Loss: -0.617199 S_loss: 0.578323\n",
      "Train Epoch: 38 [20/50 (40%)]\tG_Loss: -0.670024 S_loss: 0.570508\n",
      "Train Epoch: 38 [30/50 (60%)]\tG_Loss: -0.590761 S_loss: 0.565430\n",
      "Train Epoch: 38 [40/50 (80%)]\tG_Loss: -0.668294 S_loss: 0.565902\n",
      "\n",
      "Test set: Average loss: 1.3683, Accuracy: 6936/10000 (69.3600%)\n",
      "\n",
      "Train Epoch: 39 [0/50 (0%)]\tG_Loss: -0.643384 S_loss: 0.599398\n",
      "Train Epoch: 39 [10/50 (20%)]\tG_Loss: -0.717448 S_loss: 0.576645\n",
      "Train Epoch: 39 [20/50 (40%)]\tG_Loss: -0.631438 S_loss: 0.577447\n",
      "Train Epoch: 39 [30/50 (60%)]\tG_Loss: -0.722132 S_loss: 0.573245\n",
      "Train Epoch: 39 [40/50 (80%)]\tG_Loss: -0.719120 S_loss: 0.571886\n",
      "\n",
      "Test set: Average loss: 1.3729, Accuracy: 6852/10000 (68.5200%)\n",
      "\n",
      "Train Epoch: 40 [0/50 (0%)]\tG_Loss: -0.647229 S_loss: 0.553702\n",
      "Train Epoch: 40 [10/50 (20%)]\tG_Loss: -0.712791 S_loss: 0.606357\n",
      "Train Epoch: 40 [20/50 (40%)]\tG_Loss: -0.637628 S_loss: 0.580871\n",
      "Train Epoch: 40 [30/50 (60%)]\tG_Loss: -0.640225 S_loss: 0.584413\n",
      "Train Epoch: 40 [40/50 (80%)]\tG_Loss: -0.625448 S_loss: 0.571239\n",
      "\n",
      "Test set: Average loss: 1.6570, Accuracy: 6553/10000 (65.5300%)\n",
      "\n",
      "Train Epoch: 41 [0/50 (0%)]\tG_Loss: -0.653770 S_loss: 0.578657\n",
      "Train Epoch: 41 [10/50 (20%)]\tG_Loss: -0.630076 S_loss: 0.584332\n",
      "Train Epoch: 41 [20/50 (40%)]\tG_Loss: -0.679708 S_loss: 0.593921\n",
      "Train Epoch: 41 [30/50 (60%)]\tG_Loss: -0.627441 S_loss: 0.594562\n",
      "Train Epoch: 41 [40/50 (80%)]\tG_Loss: -0.600538 S_loss: 0.590806\n",
      "\n",
      "Test set: Average loss: 1.3740, Accuracy: 6878/10000 (68.7800%)\n",
      "\n",
      "Train Epoch: 42 [0/50 (0%)]\tG_Loss: -0.622432 S_loss: 0.571044\n",
      "Train Epoch: 42 [10/50 (20%)]\tG_Loss: -0.606953 S_loss: 0.590654\n",
      "Train Epoch: 42 [20/50 (40%)]\tG_Loss: -0.679349 S_loss: 0.573296\n",
      "Train Epoch: 42 [30/50 (60%)]\tG_Loss: -0.751478 S_loss: 0.601623\n",
      "Train Epoch: 42 [40/50 (80%)]\tG_Loss: -0.761826 S_loss: 0.577540\n",
      "\n",
      "Test set: Average loss: 1.2077, Accuracy: 7139/10000 (71.3900%)\n",
      "\n",
      "Train Epoch: 43 [0/50 (0%)]\tG_Loss: -0.671600 S_loss: 0.567215\n",
      "Train Epoch: 43 [10/50 (20%)]\tG_Loss: -0.637934 S_loss: 0.576105\n",
      "Train Epoch: 43 [20/50 (40%)]\tG_Loss: -0.633608 S_loss: 0.565349\n",
      "Train Epoch: 43 [30/50 (60%)]\tG_Loss: -0.600517 S_loss: 0.559304\n",
      "Train Epoch: 43 [40/50 (80%)]\tG_Loss: -0.681527 S_loss: 0.581795\n",
      "\n",
      "Test set: Average loss: 1.2525, Accuracy: 7083/10000 (70.8300%)\n",
      "\n",
      "Train Epoch: 44 [0/50 (0%)]\tG_Loss: -0.660028 S_loss: 0.579592\n",
      "Train Epoch: 44 [10/50 (20%)]\tG_Loss: -0.673583 S_loss: 0.543011\n",
      "Train Epoch: 44 [20/50 (40%)]\tG_Loss: -0.637655 S_loss: 0.569010\n",
      "Train Epoch: 44 [30/50 (60%)]\tG_Loss: -0.687585 S_loss: 0.567641\n",
      "Train Epoch: 44 [40/50 (80%)]\tG_Loss: -0.668876 S_loss: 0.562369\n",
      "\n",
      "Test set: Average loss: 1.7134, Accuracy: 6434/10000 (64.3400%)\n",
      "\n",
      "Train Epoch: 45 [0/50 (0%)]\tG_Loss: -0.647373 S_loss: 0.577159\n",
      "Train Epoch: 45 [10/50 (20%)]\tG_Loss: -0.660578 S_loss: 0.578264\n",
      "Train Epoch: 45 [20/50 (40%)]\tG_Loss: -0.612913 S_loss: 0.562701\n",
      "Train Epoch: 45 [30/50 (60%)]\tG_Loss: -0.619572 S_loss: 0.580751\n",
      "Train Epoch: 45 [40/50 (80%)]\tG_Loss: -0.629988 S_loss: 0.553141\n",
      "\n",
      "Test set: Average loss: 1.2260, Accuracy: 7111/10000 (71.1100%)\n",
      "\n",
      "Train Epoch: 46 [0/50 (0%)]\tG_Loss: -0.640373 S_loss: 0.574987\n",
      "Train Epoch: 46 [10/50 (20%)]\tG_Loss: -0.708714 S_loss: 0.567052\n",
      "Train Epoch: 46 [20/50 (40%)]\tG_Loss: -0.679990 S_loss: 0.573069\n",
      "Train Epoch: 46 [30/50 (60%)]\tG_Loss: -0.663643 S_loss: 0.577190\n",
      "Train Epoch: 46 [40/50 (80%)]\tG_Loss: -0.635844 S_loss: 0.559934\n",
      "\n",
      "Test set: Average loss: 1.4136, Accuracy: 6886/10000 (68.8600%)\n",
      "\n",
      "Train Epoch: 47 [0/50 (0%)]\tG_Loss: -0.665882 S_loss: 0.568806\n",
      "Train Epoch: 47 [10/50 (20%)]\tG_Loss: -0.725465 S_loss: 0.563550\n",
      "Train Epoch: 47 [20/50 (40%)]\tG_Loss: -0.653711 S_loss: 0.585961\n",
      "Train Epoch: 47 [30/50 (60%)]\tG_Loss: -0.620370 S_loss: 0.570573\n",
      "Train Epoch: 47 [40/50 (80%)]\tG_Loss: -0.626801 S_loss: 0.567541\n",
      "\n",
      "Test set: Average loss: 1.2050, Accuracy: 7088/10000 (70.8800%)\n",
      "\n",
      "Train Epoch: 48 [0/50 (0%)]\tG_Loss: -0.628300 S_loss: 0.568847\n",
      "Train Epoch: 48 [10/50 (20%)]\tG_Loss: -0.705229 S_loss: 0.570162\n",
      "Train Epoch: 48 [20/50 (40%)]\tG_Loss: -0.645102 S_loss: 0.558737\n",
      "Train Epoch: 48 [30/50 (60%)]\tG_Loss: -0.629689 S_loss: 0.562699\n",
      "Train Epoch: 48 [40/50 (80%)]\tG_Loss: -0.710533 S_loss: 0.559144\n",
      "\n",
      "Test set: Average loss: 1.5642, Accuracy: 6613/10000 (66.1300%)\n",
      "\n",
      "Train Epoch: 49 [0/50 (0%)]\tG_Loss: -0.655909 S_loss: 0.571405\n",
      "Train Epoch: 49 [10/50 (20%)]\tG_Loss: -0.654873 S_loss: 0.582151\n",
      "Train Epoch: 49 [20/50 (40%)]\tG_Loss: -0.608057 S_loss: 0.563257\n",
      "Train Epoch: 49 [30/50 (60%)]\tG_Loss: -0.626510 S_loss: 0.555893\n",
      "Train Epoch: 49 [40/50 (80%)]\tG_Loss: -0.940917 S_loss: 0.586087\n",
      "\n",
      "Test set: Average loss: 1.5499, Accuracy: 6682/10000 (66.8200%)\n",
      "\n",
      "Train Epoch: 50 [0/50 (0%)]\tG_Loss: -0.629412 S_loss: 0.553410\n",
      "Train Epoch: 50 [10/50 (20%)]\tG_Loss: -0.600178 S_loss: 0.564906\n",
      "Train Epoch: 50 [20/50 (40%)]\tG_Loss: -0.646135 S_loss: 0.559008\n",
      "Train Epoch: 50 [30/50 (60%)]\tG_Loss: -0.608131 S_loss: 0.539153\n",
      "Train Epoch: 50 [40/50 (80%)]\tG_Loss: -0.611742 S_loss: 0.571023\n",
      "\n",
      "Test set: Average loss: 1.1962, Accuracy: 7168/10000 (71.6800%)\n",
      "\n",
      "Train Epoch: 51 [0/50 (0%)]\tG_Loss: -0.664177 S_loss: 0.564416\n",
      "Train Epoch: 51 [10/50 (20%)]\tG_Loss: -0.654559 S_loss: 0.567438\n",
      "Train Epoch: 51 [20/50 (40%)]\tG_Loss: -0.643493 S_loss: 0.570424\n",
      "Train Epoch: 51 [30/50 (60%)]\tG_Loss: -0.636997 S_loss: 0.601533\n",
      "Train Epoch: 51 [40/50 (80%)]\tG_Loss: -0.654916 S_loss: 0.576675\n",
      "\n",
      "Test set: Average loss: 1.4768, Accuracy: 6806/10000 (68.0600%)\n",
      "\n",
      "Train Epoch: 52 [0/50 (0%)]\tG_Loss: -0.630594 S_loss: 0.573645\n",
      "Train Epoch: 52 [10/50 (20%)]\tG_Loss: -0.676329 S_loss: 0.573247\n",
      "Train Epoch: 52 [20/50 (40%)]\tG_Loss: -0.614454 S_loss: 0.578098\n",
      "Train Epoch: 52 [30/50 (60%)]\tG_Loss: -0.695791 S_loss: 0.568569\n",
      "Train Epoch: 52 [40/50 (80%)]\tG_Loss: -0.697239 S_loss: 0.573483\n",
      "\n",
      "Test set: Average loss: 1.3749, Accuracy: 6994/10000 (69.9400%)\n",
      "\n",
      "Train Epoch: 53 [0/50 (0%)]\tG_Loss: -0.699671 S_loss: 0.581325\n",
      "Train Epoch: 53 [10/50 (20%)]\tG_Loss: -0.685528 S_loss: 0.565623\n",
      "Train Epoch: 53 [20/50 (40%)]\tG_Loss: -0.600781 S_loss: 0.552968\n",
      "Train Epoch: 53 [30/50 (60%)]\tG_Loss: -0.651768 S_loss: 0.547759\n",
      "Train Epoch: 53 [40/50 (80%)]\tG_Loss: -0.630899 S_loss: 0.572629\n",
      "\n",
      "Test set: Average loss: 1.2257, Accuracy: 7231/10000 (72.3100%)\n",
      "\n",
      "Train Epoch: 54 [0/50 (0%)]\tG_Loss: -0.812867 S_loss: 0.579172\n",
      "Train Epoch: 54 [10/50 (20%)]\tG_Loss: -0.673455 S_loss: 0.541441\n",
      "Train Epoch: 54 [20/50 (40%)]\tG_Loss: -0.614637 S_loss: 0.569262\n",
      "Train Epoch: 54 [30/50 (60%)]\tG_Loss: -0.697193 S_loss: 0.550893\n",
      "Train Epoch: 54 [40/50 (80%)]\tG_Loss: -0.666027 S_loss: 0.544405\n",
      "\n",
      "Test set: Average loss: 1.1755, Accuracy: 7229/10000 (72.2900%)\n",
      "\n",
      "Train Epoch: 55 [0/50 (0%)]\tG_Loss: -0.561413 S_loss: 0.561216\n",
      "Train Epoch: 55 [10/50 (20%)]\tG_Loss: -0.673071 S_loss: 0.570653\n",
      "Train Epoch: 55 [20/50 (40%)]\tG_Loss: -0.598367 S_loss: 0.579687\n",
      "Train Epoch: 55 [30/50 (60%)]\tG_Loss: -0.655921 S_loss: 0.539299\n",
      "Train Epoch: 55 [40/50 (80%)]\tG_Loss: -0.631387 S_loss: 0.560053\n",
      "\n",
      "Test set: Average loss: 1.2572, Accuracy: 7171/10000 (71.7100%)\n",
      "\n",
      "Train Epoch: 56 [0/50 (0%)]\tG_Loss: -0.782205 S_loss: 0.575049\n",
      "Train Epoch: 56 [10/50 (20%)]\tG_Loss: -0.596226 S_loss: 0.559993\n",
      "Train Epoch: 56 [20/50 (40%)]\tG_Loss: -0.773571 S_loss: 0.566189\n",
      "Train Epoch: 56 [30/50 (60%)]\tG_Loss: -0.651641 S_loss: 0.552717\n",
      "Train Epoch: 56 [40/50 (80%)]\tG_Loss: -0.793688 S_loss: 0.552034\n",
      "\n",
      "Test set: Average loss: 1.5944, Accuracy: 6719/10000 (67.1900%)\n",
      "\n",
      "Train Epoch: 57 [0/50 (0%)]\tG_Loss: -0.652039 S_loss: 0.561778\n",
      "Train Epoch: 57 [10/50 (20%)]\tG_Loss: -0.629728 S_loss: 0.567202\n",
      "Train Epoch: 57 [20/50 (40%)]\tG_Loss: -0.697916 S_loss: 0.559725\n",
      "Train Epoch: 57 [30/50 (60%)]\tG_Loss: -0.876273 S_loss: 0.560872\n",
      "Train Epoch: 57 [40/50 (80%)]\tG_Loss: -0.639680 S_loss: 0.550106\n",
      "\n",
      "Test set: Average loss: 1.1602, Accuracy: 7216/10000 (72.1600%)\n",
      "\n",
      "Train Epoch: 58 [0/50 (0%)]\tG_Loss: -0.661981 S_loss: 0.551906\n",
      "Train Epoch: 58 [10/50 (20%)]\tG_Loss: -0.768212 S_loss: 0.571918\n",
      "Train Epoch: 58 [20/50 (40%)]\tG_Loss: -0.613540 S_loss: 0.566535\n",
      "Train Epoch: 58 [30/50 (60%)]\tG_Loss: -0.651946 S_loss: 0.539241\n",
      "Train Epoch: 58 [40/50 (80%)]\tG_Loss: -0.656314 S_loss: 0.586717\n",
      "\n",
      "Test set: Average loss: 1.4173, Accuracy: 6963/10000 (69.6300%)\n",
      "\n",
      "Train Epoch: 59 [0/50 (0%)]\tG_Loss: -0.601801 S_loss: 0.569831\n",
      "Train Epoch: 59 [10/50 (20%)]\tG_Loss: -0.666625 S_loss: 0.555238\n",
      "Train Epoch: 59 [20/50 (40%)]\tG_Loss: -0.630714 S_loss: 0.547704\n",
      "Train Epoch: 59 [30/50 (60%)]\tG_Loss: -0.728136 S_loss: 0.544536\n",
      "Train Epoch: 59 [40/50 (80%)]\tG_Loss: -0.585800 S_loss: 0.561525\n",
      "\n",
      "Test set: Average loss: 1.3465, Accuracy: 7022/10000 (70.2200%)\n",
      "\n",
      "Train Epoch: 60 [0/50 (0%)]\tG_Loss: -0.631889 S_loss: 0.562919\n",
      "Train Epoch: 60 [10/50 (20%)]\tG_Loss: -0.763351 S_loss: 0.535522\n",
      "Train Epoch: 60 [20/50 (40%)]\tG_Loss: -0.669219 S_loss: 0.544832\n",
      "Train Epoch: 60 [30/50 (60%)]\tG_Loss: -0.809055 S_loss: 0.539793\n",
      "Train Epoch: 60 [40/50 (80%)]\tG_Loss: -0.668144 S_loss: 0.549233\n",
      "\n",
      "Test set: Average loss: 1.1522, Accuracy: 7216/10000 (72.1600%)\n",
      "\n",
      "Train Epoch: 61 [0/50 (0%)]\tG_Loss: -0.645802 S_loss: 0.552605\n",
      "Train Epoch: 61 [10/50 (20%)]\tG_Loss: -0.732215 S_loss: 0.548139\n",
      "Train Epoch: 61 [20/50 (40%)]\tG_Loss: -0.658332 S_loss: 0.555708\n",
      "Train Epoch: 61 [30/50 (60%)]\tG_Loss: -0.671837 S_loss: 0.544926\n",
      "Train Epoch: 61 [40/50 (80%)]\tG_Loss: -0.670562 S_loss: 0.548449\n",
      "\n",
      "Test set: Average loss: 1.0984, Accuracy: 7395/10000 (73.9500%)\n",
      "\n",
      "Train Epoch: 62 [0/50 (0%)]\tG_Loss: -0.674809 S_loss: 0.556298\n",
      "Train Epoch: 62 [10/50 (20%)]\tG_Loss: -0.643690 S_loss: 0.563735\n",
      "Train Epoch: 62 [20/50 (40%)]\tG_Loss: -0.734724 S_loss: 0.558337\n",
      "Train Epoch: 62 [30/50 (60%)]\tG_Loss: -0.690608 S_loss: 0.548602\n",
      "Train Epoch: 62 [40/50 (80%)]\tG_Loss: -0.847421 S_loss: 0.554679\n",
      "\n",
      "Test set: Average loss: 1.5024, Accuracy: 6828/10000 (68.2800%)\n",
      "\n",
      "Train Epoch: 63 [0/50 (0%)]\tG_Loss: -0.772597 S_loss: 0.559351\n",
      "Train Epoch: 63 [10/50 (20%)]\tG_Loss: -0.743755 S_loss: 0.546205\n",
      "Train Epoch: 63 [20/50 (40%)]\tG_Loss: -0.815795 S_loss: 0.544624\n",
      "Train Epoch: 63 [30/50 (60%)]\tG_Loss: -0.753688 S_loss: 0.565863\n",
      "Train Epoch: 63 [40/50 (80%)]\tG_Loss: -0.678002 S_loss: 0.573712\n",
      "\n",
      "Test set: Average loss: 1.2288, Accuracy: 7210/10000 (72.1000%)\n",
      "\n",
      "Train Epoch: 64 [0/50 (0%)]\tG_Loss: -0.637895 S_loss: 0.547012\n",
      "Train Epoch: 64 [10/50 (20%)]\tG_Loss: -0.731808 S_loss: 0.553981\n",
      "Train Epoch: 64 [20/50 (40%)]\tG_Loss: -0.661882 S_loss: 0.570170\n",
      "Train Epoch: 64 [30/50 (60%)]\tG_Loss: -0.669189 S_loss: 0.569410\n",
      "Train Epoch: 64 [40/50 (80%)]\tG_Loss: -0.649294 S_loss: 0.573576\n",
      "\n",
      "Test set: Average loss: 1.1985, Accuracy: 7204/10000 (72.0400%)\n",
      "\n",
      "Train Epoch: 65 [0/50 (0%)]\tG_Loss: -0.673815 S_loss: 0.547481\n",
      "Train Epoch: 65 [10/50 (20%)]\tG_Loss: -0.681673 S_loss: 0.561349\n",
      "Train Epoch: 65 [20/50 (40%)]\tG_Loss: -0.667145 S_loss: 0.540266\n",
      "Train Epoch: 65 [30/50 (60%)]\tG_Loss: -0.641323 S_loss: 0.566605\n",
      "Train Epoch: 65 [40/50 (80%)]\tG_Loss: -0.684112 S_loss: 0.554515\n",
      "\n",
      "Test set: Average loss: 1.4513, Accuracy: 6964/10000 (69.6400%)\n",
      "\n",
      "Train Epoch: 66 [0/50 (0%)]\tG_Loss: -0.649679 S_loss: 0.561230\n",
      "Train Epoch: 66 [10/50 (20%)]\tG_Loss: -0.687702 S_loss: 0.561149\n",
      "Train Epoch: 66 [20/50 (40%)]\tG_Loss: -0.580280 S_loss: 0.543575\n",
      "Train Epoch: 66 [30/50 (60%)]\tG_Loss: -0.601636 S_loss: 0.547810\n",
      "Train Epoch: 66 [40/50 (80%)]\tG_Loss: -0.632911 S_loss: 0.540388\n",
      "\n",
      "Test set: Average loss: 1.2779, Accuracy: 7134/10000 (71.3400%)\n",
      "\n",
      "Train Epoch: 67 [0/50 (0%)]\tG_Loss: -0.633081 S_loss: 0.564569\n",
      "Train Epoch: 67 [10/50 (20%)]\tG_Loss: -0.543879 S_loss: 0.515471\n",
      "Train Epoch: 67 [20/50 (40%)]\tG_Loss: -0.517639 S_loss: 0.492747\n",
      "Train Epoch: 67 [30/50 (60%)]\tG_Loss: -0.529454 S_loss: 0.503999\n",
      "Train Epoch: 67 [40/50 (80%)]\tG_Loss: -0.489419 S_loss: 0.488369\n",
      "\n",
      "Test set: Average loss: 1.0963, Accuracy: 7511/10000 (75.1100%)\n",
      "\n",
      "Train Epoch: 68 [0/50 (0%)]\tG_Loss: -0.502819 S_loss: 0.504173\n",
      "Train Epoch: 68 [10/50 (20%)]\tG_Loss: -0.497731 S_loss: 0.490797\n",
      "Train Epoch: 68 [20/50 (40%)]\tG_Loss: -0.516756 S_loss: 0.507787\n",
      "Train Epoch: 68 [30/50 (60%)]\tG_Loss: -0.537350 S_loss: 0.496043\n",
      "Train Epoch: 68 [40/50 (80%)]\tG_Loss: -0.547782 S_loss: 0.476815\n",
      "\n",
      "Test set: Average loss: 1.0555, Accuracy: 7581/10000 (75.8100%)\n",
      "\n",
      "Train Epoch: 69 [0/50 (0%)]\tG_Loss: -0.506269 S_loss: 0.491187\n",
      "Train Epoch: 69 [10/50 (20%)]\tG_Loss: -0.490641 S_loss: 0.462844\n",
      "Train Epoch: 69 [20/50 (40%)]\tG_Loss: -0.512740 S_loss: 0.497506\n",
      "Train Epoch: 69 [30/50 (60%)]\tG_Loss: -0.513155 S_loss: 0.483738\n",
      "Train Epoch: 69 [40/50 (80%)]\tG_Loss: -0.522317 S_loss: 0.476610\n",
      "\n",
      "Test set: Average loss: 1.0723, Accuracy: 7503/10000 (75.0300%)\n",
      "\n",
      "Train Epoch: 70 [0/50 (0%)]\tG_Loss: -0.488312 S_loss: 0.485078\n",
      "Train Epoch: 70 [10/50 (20%)]\tG_Loss: -0.484431 S_loss: 0.506091\n",
      "Train Epoch: 70 [20/50 (40%)]\tG_Loss: -0.522922 S_loss: 0.481348\n",
      "Train Epoch: 70 [30/50 (60%)]\tG_Loss: -0.506459 S_loss: 0.484418\n",
      "Train Epoch: 70 [40/50 (80%)]\tG_Loss: -0.483746 S_loss: 0.484655\n",
      "\n",
      "Test set: Average loss: 1.0930, Accuracy: 7486/10000 (74.8600%)\n",
      "\n",
      "Train Epoch: 71 [0/50 (0%)]\tG_Loss: -0.514811 S_loss: 0.493660\n",
      "Train Epoch: 71 [10/50 (20%)]\tG_Loss: -0.478886 S_loss: 0.485037\n",
      "Train Epoch: 71 [20/50 (40%)]\tG_Loss: -0.483270 S_loss: 0.494329\n",
      "Train Epoch: 71 [30/50 (60%)]\tG_Loss: -0.509945 S_loss: 0.475031\n",
      "Train Epoch: 71 [40/50 (80%)]\tG_Loss: -0.537145 S_loss: 0.479142\n",
      "\n",
      "Test set: Average loss: 1.1062, Accuracy: 7491/10000 (74.9100%)\n",
      "\n",
      "Train Epoch: 72 [0/50 (0%)]\tG_Loss: -0.496198 S_loss: 0.465567\n",
      "Train Epoch: 72 [10/50 (20%)]\tG_Loss: -0.533868 S_loss: 0.485857\n",
      "Train Epoch: 72 [20/50 (40%)]\tG_Loss: -0.506994 S_loss: 0.461433\n",
      "Train Epoch: 72 [30/50 (60%)]\tG_Loss: -0.488684 S_loss: 0.480761\n",
      "Train Epoch: 72 [40/50 (80%)]\tG_Loss: -0.509476 S_loss: 0.480172\n",
      "\n",
      "Test set: Average loss: 1.1288, Accuracy: 7492/10000 (74.9200%)\n",
      "\n",
      "Train Epoch: 73 [0/50 (0%)]\tG_Loss: -0.516073 S_loss: 0.453083\n",
      "Train Epoch: 73 [10/50 (20%)]\tG_Loss: -0.488049 S_loss: 0.454303\n",
      "Train Epoch: 73 [20/50 (40%)]\tG_Loss: -0.510301 S_loss: 0.477080\n",
      "Train Epoch: 73 [30/50 (60%)]\tG_Loss: -0.520770 S_loss: 0.470248\n",
      "Train Epoch: 73 [40/50 (80%)]\tG_Loss: -0.525421 S_loss: 0.488668\n",
      "\n",
      "Test set: Average loss: 1.0160, Accuracy: 7678/10000 (76.7800%)\n",
      "\n",
      "Train Epoch: 74 [0/50 (0%)]\tG_Loss: -0.495684 S_loss: 0.478344\n",
      "Train Epoch: 74 [10/50 (20%)]\tG_Loss: -0.503064 S_loss: 0.496183\n",
      "Train Epoch: 74 [20/50 (40%)]\tG_Loss: -0.491473 S_loss: 0.477227\n",
      "Train Epoch: 74 [30/50 (60%)]\tG_Loss: -0.498907 S_loss: 0.481970\n",
      "Train Epoch: 74 [40/50 (80%)]\tG_Loss: -0.465172 S_loss: 0.457348\n",
      "\n",
      "Test set: Average loss: 1.0575, Accuracy: 7599/10000 (75.9900%)\n",
      "\n",
      "Train Epoch: 75 [0/50 (0%)]\tG_Loss: -0.504479 S_loss: 0.475514\n",
      "Train Epoch: 75 [10/50 (20%)]\tG_Loss: -0.506540 S_loss: 0.474534\n",
      "Train Epoch: 75 [20/50 (40%)]\tG_Loss: -0.488064 S_loss: 0.471738\n",
      "Train Epoch: 75 [30/50 (60%)]\tG_Loss: -0.499539 S_loss: 0.476949\n",
      "Train Epoch: 75 [40/50 (80%)]\tG_Loss: -0.476442 S_loss: 0.467131\n",
      "\n",
      "Test set: Average loss: 1.0183, Accuracy: 7683/10000 (76.8300%)\n",
      "\n",
      "Train Epoch: 76 [0/50 (0%)]\tG_Loss: -0.476696 S_loss: 0.477847\n",
      "Train Epoch: 76 [10/50 (20%)]\tG_Loss: -0.485882 S_loss: 0.470716\n",
      "Train Epoch: 76 [20/50 (40%)]\tG_Loss: -0.478675 S_loss: 0.484663\n",
      "Train Epoch: 76 [30/50 (60%)]\tG_Loss: -0.494287 S_loss: 0.473131\n",
      "Train Epoch: 76 [40/50 (80%)]\tG_Loss: -0.499772 S_loss: 0.459923\n",
      "\n",
      "Test set: Average loss: 0.9413, Accuracy: 7855/10000 (78.5500%)\n",
      "\n",
      "Train Epoch: 77 [0/50 (0%)]\tG_Loss: -0.506998 S_loss: 0.494144\n",
      "Train Epoch: 77 [10/50 (20%)]\tG_Loss: -0.561390 S_loss: 0.463663\n",
      "Train Epoch: 77 [20/50 (40%)]\tG_Loss: -0.484296 S_loss: 0.483167\n",
      "Train Epoch: 77 [30/50 (60%)]\tG_Loss: -0.478802 S_loss: 0.463334\n",
      "Train Epoch: 77 [40/50 (80%)]\tG_Loss: -0.501618 S_loss: 0.475916\n",
      "\n",
      "Test set: Average loss: 0.9624, Accuracy: 7785/10000 (77.8500%)\n",
      "\n",
      "Train Epoch: 78 [0/50 (0%)]\tG_Loss: -0.494808 S_loss: 0.465108\n",
      "Train Epoch: 78 [10/50 (20%)]\tG_Loss: -0.473986 S_loss: 0.471538\n",
      "Train Epoch: 78 [20/50 (40%)]\tG_Loss: -0.549714 S_loss: 0.479660\n",
      "Train Epoch: 78 [30/50 (60%)]\tG_Loss: -0.485721 S_loss: 0.481904\n",
      "Train Epoch: 78 [40/50 (80%)]\tG_Loss: -0.474304 S_loss: 0.469550\n",
      "\n",
      "Test set: Average loss: 1.0528, Accuracy: 7606/10000 (76.0600%)\n",
      "\n",
      "Train Epoch: 79 [0/50 (0%)]\tG_Loss: -0.579723 S_loss: 0.483973\n",
      "Train Epoch: 79 [10/50 (20%)]\tG_Loss: -0.487608 S_loss: 0.458315\n",
      "Train Epoch: 79 [20/50 (40%)]\tG_Loss: -0.475231 S_loss: 0.475725\n",
      "Train Epoch: 79 [30/50 (60%)]\tG_Loss: -0.508247 S_loss: 0.459895\n",
      "Train Epoch: 79 [40/50 (80%)]\tG_Loss: -0.475510 S_loss: 0.472472\n",
      "\n",
      "Test set: Average loss: 1.0138, Accuracy: 7703/10000 (77.0300%)\n",
      "\n",
      "Train Epoch: 80 [0/50 (0%)]\tG_Loss: -0.490133 S_loss: 0.482869\n",
      "Train Epoch: 80 [10/50 (20%)]\tG_Loss: -0.538499 S_loss: 0.472411\n",
      "Train Epoch: 80 [20/50 (40%)]\tG_Loss: -0.491356 S_loss: 0.470590\n",
      "Train Epoch: 80 [30/50 (60%)]\tG_Loss: -0.501344 S_loss: 0.459745\n",
      "Train Epoch: 80 [40/50 (80%)]\tG_Loss: -0.481428 S_loss: 0.462234\n",
      "\n",
      "Test set: Average loss: 0.9248, Accuracy: 7784/10000 (77.8400%)\n",
      "\n",
      "Train Epoch: 81 [0/50 (0%)]\tG_Loss: -0.471043 S_loss: 0.483884\n",
      "Train Epoch: 81 [10/50 (20%)]\tG_Loss: -0.487542 S_loss: 0.484923\n",
      "Train Epoch: 81 [20/50 (40%)]\tG_Loss: -0.509117 S_loss: 0.467586\n",
      "Train Epoch: 81 [30/50 (60%)]\tG_Loss: -0.517243 S_loss: 0.464931\n",
      "Train Epoch: 81 [40/50 (80%)]\tG_Loss: -0.520219 S_loss: 0.463936\n",
      "\n",
      "Test set: Average loss: 0.9326, Accuracy: 7770/10000 (77.7000%)\n",
      "\n",
      "Train Epoch: 82 [0/50 (0%)]\tG_Loss: -0.512648 S_loss: 0.447677\n",
      "Train Epoch: 82 [10/50 (20%)]\tG_Loss: -0.467629 S_loss: 0.473714\n",
      "Train Epoch: 82 [20/50 (40%)]\tG_Loss: -0.501998 S_loss: 0.472258\n",
      "Train Epoch: 82 [30/50 (60%)]\tG_Loss: -0.508763 S_loss: 0.459899\n",
      "Train Epoch: 82 [40/50 (80%)]\tG_Loss: -0.488934 S_loss: 0.484072\n",
      "\n",
      "Test set: Average loss: 0.9346, Accuracy: 7790/10000 (77.9000%)\n",
      "\n",
      "Train Epoch: 83 [0/50 (0%)]\tG_Loss: -0.535261 S_loss: 0.481501\n",
      "Train Epoch: 83 [10/50 (20%)]\tG_Loss: -0.487513 S_loss: 0.471433\n",
      "Train Epoch: 83 [20/50 (40%)]\tG_Loss: -0.485671 S_loss: 0.473139\n",
      "Train Epoch: 83 [30/50 (60%)]\tG_Loss: -0.503873 S_loss: 0.475727\n",
      "Train Epoch: 83 [40/50 (80%)]\tG_Loss: -0.485266 S_loss: 0.462106\n",
      "\n",
      "Test set: Average loss: 0.9592, Accuracy: 7793/10000 (77.9300%)\n",
      "\n",
      "Train Epoch: 84 [0/50 (0%)]\tG_Loss: -0.489803 S_loss: 0.480562\n",
      "Train Epoch: 84 [10/50 (20%)]\tG_Loss: -0.512141 S_loss: 0.461058\n",
      "Train Epoch: 84 [20/50 (40%)]\tG_Loss: -0.503445 S_loss: 0.451775\n",
      "Train Epoch: 84 [30/50 (60%)]\tG_Loss: -0.527966 S_loss: 0.482699\n",
      "Train Epoch: 84 [40/50 (80%)]\tG_Loss: -0.555160 S_loss: 0.457995\n",
      "\n",
      "Test set: Average loss: 0.9327, Accuracy: 7823/10000 (78.2300%)\n",
      "\n",
      "Train Epoch: 85 [0/50 (0%)]\tG_Loss: -0.479578 S_loss: 0.461846\n",
      "Train Epoch: 85 [10/50 (20%)]\tG_Loss: -0.479587 S_loss: 0.470679\n",
      "Train Epoch: 85 [20/50 (40%)]\tG_Loss: -0.468116 S_loss: 0.473005\n",
      "Train Epoch: 85 [30/50 (60%)]\tG_Loss: -0.492681 S_loss: 0.456170\n",
      "Train Epoch: 85 [40/50 (80%)]\tG_Loss: -0.575556 S_loss: 0.462167\n",
      "\n",
      "Test set: Average loss: 0.9232, Accuracy: 7937/10000 (79.3700%)\n",
      "\n",
      "Train Epoch: 86 [0/50 (0%)]\tG_Loss: -0.484571 S_loss: 0.479389\n",
      "Train Epoch: 86 [10/50 (20%)]\tG_Loss: -0.503636 S_loss: 0.479299\n",
      "Train Epoch: 86 [20/50 (40%)]\tG_Loss: -0.522206 S_loss: 0.467809\n",
      "Train Epoch: 86 [30/50 (60%)]\tG_Loss: -0.513462 S_loss: 0.472343\n",
      "Train Epoch: 86 [40/50 (80%)]\tG_Loss: -0.509622 S_loss: 0.477360\n",
      "\n",
      "Test set: Average loss: 0.8980, Accuracy: 7912/10000 (79.1200%)\n",
      "\n",
      "Train Epoch: 87 [0/50 (0%)]\tG_Loss: -0.467771 S_loss: 0.481627\n",
      "Train Epoch: 87 [10/50 (20%)]\tG_Loss: -0.508229 S_loss: 0.465401\n",
      "Train Epoch: 87 [20/50 (40%)]\tG_Loss: -0.484738 S_loss: 0.480008\n",
      "Train Epoch: 87 [30/50 (60%)]\tG_Loss: -0.530201 S_loss: 0.452186\n",
      "Train Epoch: 87 [40/50 (80%)]\tG_Loss: -0.534103 S_loss: 0.471146\n",
      "\n",
      "Test set: Average loss: 0.9134, Accuracy: 7881/10000 (78.8100%)\n",
      "\n",
      "Train Epoch: 88 [0/50 (0%)]\tG_Loss: -0.506434 S_loss: 0.472858\n",
      "Train Epoch: 88 [10/50 (20%)]\tG_Loss: -0.477327 S_loss: 0.455135\n",
      "Train Epoch: 88 [20/50 (40%)]\tG_Loss: -0.492178 S_loss: 0.459986\n",
      "Train Epoch: 88 [30/50 (60%)]\tG_Loss: -0.467713 S_loss: 0.476657\n",
      "Train Epoch: 88 [40/50 (80%)]\tG_Loss: -0.485136 S_loss: 0.467585\n",
      "\n",
      "Test set: Average loss: 0.9181, Accuracy: 7907/10000 (79.0700%)\n",
      "\n",
      "Train Epoch: 89 [0/50 (0%)]\tG_Loss: -0.480522 S_loss: 0.466825\n",
      "Train Epoch: 89 [10/50 (20%)]\tG_Loss: -0.542066 S_loss: 0.477391\n",
      "Train Epoch: 89 [20/50 (40%)]\tG_Loss: -0.514159 S_loss: 0.468233\n",
      "Train Epoch: 89 [30/50 (60%)]\tG_Loss: -0.506311 S_loss: 0.475025\n",
      "Train Epoch: 89 [40/50 (80%)]\tG_Loss: -0.492367 S_loss: 0.458843\n",
      "\n",
      "Test set: Average loss: 0.8649, Accuracy: 8045/10000 (80.4500%)\n",
      "\n",
      "Train Epoch: 90 [0/50 (0%)]\tG_Loss: -0.498570 S_loss: 0.462506\n",
      "Train Epoch: 90 [10/50 (20%)]\tG_Loss: -0.551322 S_loss: 0.468496\n",
      "Train Epoch: 90 [20/50 (40%)]\tG_Loss: -0.477500 S_loss: 0.488565\n",
      "Train Epoch: 90 [30/50 (60%)]\tG_Loss: -0.509088 S_loss: 0.454626\n",
      "Train Epoch: 90 [40/50 (80%)]\tG_Loss: -0.486213 S_loss: 0.470703\n",
      "\n",
      "Test set: Average loss: 0.8624, Accuracy: 7973/10000 (79.7300%)\n",
      "\n",
      "Train Epoch: 91 [0/50 (0%)]\tG_Loss: -0.500852 S_loss: 0.476472\n",
      "Train Epoch: 91 [10/50 (20%)]\tG_Loss: -0.470405 S_loss: 0.452888\n",
      "Train Epoch: 91 [20/50 (40%)]\tG_Loss: -0.520019 S_loss: 0.457778\n",
      "Train Epoch: 91 [30/50 (60%)]\tG_Loss: -0.557626 S_loss: 0.483256\n",
      "Train Epoch: 91 [40/50 (80%)]\tG_Loss: -0.537203 S_loss: 0.460084\n",
      "\n",
      "Test set: Average loss: 0.8233, Accuracy: 8057/10000 (80.5700%)\n",
      "\n",
      "Train Epoch: 92 [0/50 (0%)]\tG_Loss: -0.499898 S_loss: 0.443047\n",
      "Train Epoch: 92 [10/50 (20%)]\tG_Loss: -0.477857 S_loss: 0.469163\n",
      "Train Epoch: 92 [20/50 (40%)]\tG_Loss: -0.521403 S_loss: 0.461757\n",
      "Train Epoch: 92 [30/50 (60%)]\tG_Loss: -0.516721 S_loss: 0.480351\n",
      "Train Epoch: 92 [40/50 (80%)]\tG_Loss: -0.482630 S_loss: 0.474587\n",
      "\n",
      "Test set: Average loss: 0.8239, Accuracy: 8020/10000 (80.2000%)\n",
      "\n",
      "Train Epoch: 93 [0/50 (0%)]\tG_Loss: -0.489418 S_loss: 0.458586\n",
      "Train Epoch: 93 [10/50 (20%)]\tG_Loss: -0.501614 S_loss: 0.475102\n",
      "Train Epoch: 93 [20/50 (40%)]\tG_Loss: -0.506521 S_loss: 0.478488\n",
      "Train Epoch: 93 [30/50 (60%)]\tG_Loss: -0.498104 S_loss: 0.468404\n",
      "Train Epoch: 93 [40/50 (80%)]\tG_Loss: -0.469828 S_loss: 0.458404\n",
      "\n",
      "Test set: Average loss: 0.8812, Accuracy: 7942/10000 (79.4200%)\n",
      "\n",
      "Train Epoch: 94 [0/50 (0%)]\tG_Loss: -0.483838 S_loss: 0.449673\n",
      "Train Epoch: 94 [10/50 (20%)]\tG_Loss: -0.479778 S_loss: 0.458793\n",
      "Train Epoch: 94 [20/50 (40%)]\tG_Loss: -0.491551 S_loss: 0.466655\n",
      "Train Epoch: 94 [30/50 (60%)]\tG_Loss: -0.476647 S_loss: 0.459845\n",
      "Train Epoch: 94 [40/50 (80%)]\tG_Loss: -0.482693 S_loss: 0.469462\n",
      "\n",
      "Test set: Average loss: 0.8985, Accuracy: 7886/10000 (78.8600%)\n",
      "\n",
      "Train Epoch: 95 [0/50 (0%)]\tG_Loss: -0.461258 S_loss: 0.453857\n",
      "Train Epoch: 95 [10/50 (20%)]\tG_Loss: -0.484826 S_loss: 0.456107\n",
      "Train Epoch: 95 [20/50 (40%)]\tG_Loss: -0.494262 S_loss: 0.469114\n",
      "Train Epoch: 95 [30/50 (60%)]\tG_Loss: -0.523710 S_loss: 0.452943\n",
      "Train Epoch: 95 [40/50 (80%)]\tG_Loss: -0.510946 S_loss: 0.455011\n",
      "\n",
      "Test set: Average loss: 0.8279, Accuracy: 8065/10000 (80.6500%)\n",
      "\n",
      "Train Epoch: 96 [0/50 (0%)]\tG_Loss: -0.514818 S_loss: 0.465511\n",
      "Train Epoch: 96 [10/50 (20%)]\tG_Loss: -0.503588 S_loss: 0.480403\n",
      "Train Epoch: 96 [20/50 (40%)]\tG_Loss: -0.538667 S_loss: 0.457640\n",
      "Train Epoch: 96 [30/50 (60%)]\tG_Loss: -0.511368 S_loss: 0.465786\n",
      "Train Epoch: 96 [40/50 (80%)]\tG_Loss: -0.489895 S_loss: 0.474682\n",
      "\n",
      "Test set: Average loss: 0.8498, Accuracy: 7956/10000 (79.5600%)\n",
      "\n",
      "Train Epoch: 97 [0/50 (0%)]\tG_Loss: -0.500945 S_loss: 0.449907\n",
      "Train Epoch: 97 [10/50 (20%)]\tG_Loss: -0.495582 S_loss: 0.450661\n",
      "Train Epoch: 97 [20/50 (40%)]\tG_Loss: -0.474283 S_loss: 0.449066\n",
      "Train Epoch: 97 [30/50 (60%)]\tG_Loss: -0.513186 S_loss: 0.462684\n",
      "Train Epoch: 97 [40/50 (80%)]\tG_Loss: -0.505905 S_loss: 0.476921\n",
      "\n",
      "Test set: Average loss: 0.8490, Accuracy: 8003/10000 (80.0300%)\n",
      "\n",
      "Train Epoch: 98 [0/50 (0%)]\tG_Loss: -0.477932 S_loss: 0.464766\n",
      "Train Epoch: 98 [10/50 (20%)]\tG_Loss: -0.492009 S_loss: 0.446871\n",
      "Train Epoch: 98 [20/50 (40%)]\tG_Loss: -0.529755 S_loss: 0.466585\n",
      "Train Epoch: 98 [30/50 (60%)]\tG_Loss: -0.517847 S_loss: 0.459196\n",
      "Train Epoch: 98 [40/50 (80%)]\tG_Loss: -0.525759 S_loss: 0.460099\n",
      "\n",
      "Test set: Average loss: 0.8068, Accuracy: 8118/10000 (81.1800%)\n",
      "\n",
      "Train Epoch: 99 [0/50 (0%)]\tG_Loss: -0.579772 S_loss: 0.472947\n",
      "Train Epoch: 99 [10/50 (20%)]\tG_Loss: -0.496319 S_loss: 0.457098\n",
      "Train Epoch: 99 [20/50 (40%)]\tG_Loss: -0.486915 S_loss: 0.465006\n",
      "Train Epoch: 99 [30/50 (60%)]\tG_Loss: -0.520388 S_loss: 0.468761\n",
      "Train Epoch: 99 [40/50 (80%)]\tG_Loss: -0.505799 S_loss: 0.483593\n",
      "\n",
      "Test set: Average loss: 0.8807, Accuracy: 8011/10000 (80.1100%)\n",
      "\n",
      "Train Epoch: 100 [0/50 (0%)]\tG_Loss: -0.544307 S_loss: 0.459110\n",
      "Train Epoch: 100 [10/50 (20%)]\tG_Loss: -0.481939 S_loss: 0.478154\n",
      "Train Epoch: 100 [20/50 (40%)]\tG_Loss: -0.487697 S_loss: 0.452319\n",
      "Train Epoch: 100 [30/50 (60%)]\tG_Loss: -0.487544 S_loss: 0.467976\n",
      "Train Epoch: 100 [40/50 (80%)]\tG_Loss: -0.487096 S_loss: 0.462168\n",
      "\n",
      "Test set: Average loss: 0.8217, Accuracy: 8060/10000 (80.6000%)\n",
      "\n",
      "Train Epoch: 101 [0/50 (0%)]\tG_Loss: -0.480713 S_loss: 0.458480\n",
      "Train Epoch: 101 [10/50 (20%)]\tG_Loss: -0.459254 S_loss: 0.450613\n",
      "Train Epoch: 101 [20/50 (40%)]\tG_Loss: -0.589537 S_loss: 0.453510\n",
      "Train Epoch: 101 [30/50 (60%)]\tG_Loss: -0.513573 S_loss: 0.466863\n",
      "Train Epoch: 101 [40/50 (80%)]\tG_Loss: -0.486549 S_loss: 0.462288\n",
      "\n",
      "Test set: Average loss: 0.8696, Accuracy: 7964/10000 (79.6400%)\n",
      "\n",
      "Train Epoch: 102 [0/50 (0%)]\tG_Loss: -0.556710 S_loss: 0.475358\n",
      "Train Epoch: 102 [10/50 (20%)]\tG_Loss: -0.499983 S_loss: 0.461930\n",
      "Train Epoch: 102 [20/50 (40%)]\tG_Loss: -0.487068 S_loss: 0.436693\n",
      "Train Epoch: 102 [30/50 (60%)]\tG_Loss: -0.503623 S_loss: 0.475851\n",
      "Train Epoch: 102 [40/50 (80%)]\tG_Loss: -0.470977 S_loss: 0.463613\n",
      "\n",
      "Test set: Average loss: 0.7214, Accuracy: 8267/10000 (82.6700%)\n",
      "\n",
      "Train Epoch: 103 [0/50 (0%)]\tG_Loss: -0.505276 S_loss: 0.457610\n",
      "Train Epoch: 103 [10/50 (20%)]\tG_Loss: -0.480690 S_loss: 0.456170\n",
      "Train Epoch: 103 [20/50 (40%)]\tG_Loss: -0.520572 S_loss: 0.479169\n",
      "Train Epoch: 103 [30/50 (60%)]\tG_Loss: -0.477894 S_loss: 0.449492\n",
      "Train Epoch: 103 [40/50 (80%)]\tG_Loss: -0.489643 S_loss: 0.453679\n",
      "\n",
      "Test set: Average loss: 0.8254, Accuracy: 8052/10000 (80.5200%)\n",
      "\n",
      "Train Epoch: 104 [0/50 (0%)]\tG_Loss: -0.475130 S_loss: 0.456224\n",
      "Train Epoch: 104 [10/50 (20%)]\tG_Loss: -0.497434 S_loss: 0.475029\n",
      "Train Epoch: 104 [20/50 (40%)]\tG_Loss: -0.499129 S_loss: 0.449691\n",
      "Train Epoch: 104 [30/50 (60%)]\tG_Loss: -0.523523 S_loss: 0.456775\n",
      "Train Epoch: 104 [40/50 (80%)]\tG_Loss: -0.489747 S_loss: 0.482702\n",
      "\n",
      "Test set: Average loss: 0.8133, Accuracy: 8014/10000 (80.1400%)\n",
      "\n",
      "Train Epoch: 105 [0/50 (0%)]\tG_Loss: -0.498325 S_loss: 0.462692\n",
      "Train Epoch: 105 [10/50 (20%)]\tG_Loss: -0.492053 S_loss: 0.473879\n",
      "Train Epoch: 105 [20/50 (40%)]\tG_Loss: -0.481492 S_loss: 0.475727\n",
      "Train Epoch: 105 [30/50 (60%)]\tG_Loss: -0.513115 S_loss: 0.462848\n",
      "Train Epoch: 105 [40/50 (80%)]\tG_Loss: -0.509560 S_loss: 0.470130\n",
      "\n",
      "Test set: Average loss: 0.7915, Accuracy: 8098/10000 (80.9800%)\n",
      "\n",
      "Train Epoch: 106 [0/50 (0%)]\tG_Loss: -0.558043 S_loss: 0.456337\n",
      "Train Epoch: 106 [10/50 (20%)]\tG_Loss: -0.503276 S_loss: 0.451854\n",
      "Train Epoch: 106 [20/50 (40%)]\tG_Loss: -0.466175 S_loss: 0.464637\n",
      "Train Epoch: 106 [30/50 (60%)]\tG_Loss: -0.476665 S_loss: 0.473777\n",
      "Train Epoch: 106 [40/50 (80%)]\tG_Loss: -0.509227 S_loss: 0.474786\n",
      "\n",
      "Test set: Average loss: 0.7319, Accuracy: 8240/10000 (82.4000%)\n",
      "\n",
      "Train Epoch: 107 [0/50 (0%)]\tG_Loss: -0.636760 S_loss: 0.463621\n",
      "Train Epoch: 107 [10/50 (20%)]\tG_Loss: -0.449812 S_loss: 0.486986\n",
      "Train Epoch: 107 [20/50 (40%)]\tG_Loss: -0.497956 S_loss: 0.473245\n",
      "Train Epoch: 107 [30/50 (60%)]\tG_Loss: -0.465307 S_loss: 0.471340\n",
      "Train Epoch: 107 [40/50 (80%)]\tG_Loss: -0.496575 S_loss: 0.455532\n",
      "\n",
      "Test set: Average loss: 0.7954, Accuracy: 8124/10000 (81.2400%)\n",
      "\n",
      "Train Epoch: 108 [0/50 (0%)]\tG_Loss: -0.531759 S_loss: 0.483295\n",
      "Train Epoch: 108 [10/50 (20%)]\tG_Loss: -0.541018 S_loss: 0.460324\n",
      "Train Epoch: 108 [20/50 (40%)]\tG_Loss: -0.519349 S_loss: 0.457092\n",
      "Train Epoch: 108 [30/50 (60%)]\tG_Loss: -0.491037 S_loss: 0.455133\n",
      "Train Epoch: 108 [40/50 (80%)]\tG_Loss: -0.542414 S_loss: 0.490168\n",
      "\n",
      "Test set: Average loss: 0.8862, Accuracy: 7987/10000 (79.8700%)\n",
      "\n",
      "Train Epoch: 109 [0/50 (0%)]\tG_Loss: -0.541885 S_loss: 0.479031\n",
      "Train Epoch: 109 [10/50 (20%)]\tG_Loss: -0.512330 S_loss: 0.469064\n",
      "Train Epoch: 109 [20/50 (40%)]\tG_Loss: -0.491054 S_loss: 0.460831\n",
      "Train Epoch: 109 [30/50 (60%)]\tG_Loss: -0.478072 S_loss: 0.460408\n",
      "Train Epoch: 109 [40/50 (80%)]\tG_Loss: -0.529896 S_loss: 0.453266\n",
      "\n",
      "Test set: Average loss: 0.7989, Accuracy: 8082/10000 (80.8200%)\n",
      "\n",
      "Train Epoch: 110 [0/50 (0%)]\tG_Loss: -0.541158 S_loss: 0.469723\n",
      "Train Epoch: 110 [10/50 (20%)]\tG_Loss: -0.494917 S_loss: 0.437257\n",
      "Train Epoch: 110 [20/50 (40%)]\tG_Loss: -0.496457 S_loss: 0.461658\n",
      "Train Epoch: 110 [30/50 (60%)]\tG_Loss: -0.498533 S_loss: 0.469862\n",
      "Train Epoch: 110 [40/50 (80%)]\tG_Loss: -0.452405 S_loss: 0.449696\n",
      "\n",
      "Test set: Average loss: 0.8148, Accuracy: 8068/10000 (80.6800%)\n",
      "\n",
      "Train Epoch: 111 [0/50 (0%)]\tG_Loss: -0.531915 S_loss: 0.466120\n",
      "Train Epoch: 111 [10/50 (20%)]\tG_Loss: -0.469164 S_loss: 0.455401\n",
      "Train Epoch: 111 [20/50 (40%)]\tG_Loss: -0.485634 S_loss: 0.473788\n",
      "Train Epoch: 111 [30/50 (60%)]\tG_Loss: -0.586075 S_loss: 0.463750\n",
      "Train Epoch: 111 [40/50 (80%)]\tG_Loss: -0.533397 S_loss: 0.453204\n",
      "\n",
      "Test set: Average loss: 0.7624, Accuracy: 8227/10000 (82.2700%)\n",
      "\n",
      "Train Epoch: 112 [0/50 (0%)]\tG_Loss: -0.480795 S_loss: 0.428736\n",
      "Train Epoch: 112 [10/50 (20%)]\tG_Loss: -0.437970 S_loss: 0.433817\n",
      "Train Epoch: 112 [20/50 (40%)]\tG_Loss: -0.417008 S_loss: 0.425671\n",
      "Train Epoch: 112 [30/50 (60%)]\tG_Loss: -0.434157 S_loss: 0.414706\n",
      "Train Epoch: 112 [40/50 (80%)]\tG_Loss: -0.418592 S_loss: 0.428113\n",
      "\n",
      "Test set: Average loss: 0.7182, Accuracy: 8288/10000 (82.8800%)\n",
      "\n",
      "Train Epoch: 113 [0/50 (0%)]\tG_Loss: -0.433544 S_loss: 0.425169\n",
      "Train Epoch: 113 [10/50 (20%)]\tG_Loss: -0.433999 S_loss: 0.422860\n",
      "Train Epoch: 113 [20/50 (40%)]\tG_Loss: -0.425277 S_loss: 0.423696\n",
      "Train Epoch: 113 [30/50 (60%)]\tG_Loss: -0.423705 S_loss: 0.422745\n",
      "Train Epoch: 113 [40/50 (80%)]\tG_Loss: -0.425098 S_loss: 0.443098\n",
      "\n",
      "Test set: Average loss: 0.7152, Accuracy: 8292/10000 (82.9200%)\n",
      "\n",
      "Train Epoch: 114 [0/50 (0%)]\tG_Loss: -0.419854 S_loss: 0.418265\n",
      "Train Epoch: 114 [10/50 (20%)]\tG_Loss: -0.430153 S_loss: 0.424275\n",
      "Train Epoch: 114 [20/50 (40%)]\tG_Loss: -0.433957 S_loss: 0.441706\n",
      "Train Epoch: 114 [30/50 (60%)]\tG_Loss: -0.420771 S_loss: 0.424408\n",
      "Train Epoch: 114 [40/50 (80%)]\tG_Loss: -0.437306 S_loss: 0.436306\n",
      "\n",
      "Test set: Average loss: 0.6846, Accuracy: 8411/10000 (84.1100%)\n",
      "\n",
      "Train Epoch: 115 [0/50 (0%)]\tG_Loss: -0.433117 S_loss: 0.443165\n",
      "Train Epoch: 115 [10/50 (20%)]\tG_Loss: -0.415177 S_loss: 0.441581\n",
      "Train Epoch: 115 [20/50 (40%)]\tG_Loss: -0.411507 S_loss: 0.426663\n",
      "Train Epoch: 115 [30/50 (60%)]\tG_Loss: -0.423590 S_loss: 0.414463\n",
      "Train Epoch: 115 [40/50 (80%)]\tG_Loss: -0.423116 S_loss: 0.414310\n",
      "\n",
      "Test set: Average loss: 0.7111, Accuracy: 8287/10000 (82.8700%)\n",
      "\n",
      "Train Epoch: 116 [0/50 (0%)]\tG_Loss: -0.439171 S_loss: 0.412174\n",
      "Train Epoch: 116 [10/50 (20%)]\tG_Loss: -0.414339 S_loss: 0.420564\n",
      "Train Epoch: 116 [20/50 (40%)]\tG_Loss: -0.417129 S_loss: 0.449416\n",
      "Train Epoch: 116 [30/50 (60%)]\tG_Loss: -0.425891 S_loss: 0.424976\n",
      "Train Epoch: 116 [40/50 (80%)]\tG_Loss: -0.418118 S_loss: 0.425735\n",
      "\n",
      "Test set: Average loss: 0.7090, Accuracy: 8321/10000 (83.2100%)\n",
      "\n",
      "Train Epoch: 117 [0/50 (0%)]\tG_Loss: -0.408585 S_loss: 0.418136\n",
      "Train Epoch: 117 [10/50 (20%)]\tG_Loss: -0.422292 S_loss: 0.428317\n",
      "Train Epoch: 117 [20/50 (40%)]\tG_Loss: -0.425701 S_loss: 0.406563\n",
      "Train Epoch: 117 [30/50 (60%)]\tG_Loss: -0.407941 S_loss: 0.409612\n",
      "Train Epoch: 117 [40/50 (80%)]\tG_Loss: -0.421585 S_loss: 0.433785\n",
      "\n",
      "Test set: Average loss: 0.7049, Accuracy: 8342/10000 (83.4200%)\n",
      "\n",
      "Train Epoch: 118 [0/50 (0%)]\tG_Loss: -0.404895 S_loss: 0.433253\n",
      "Train Epoch: 118 [10/50 (20%)]\tG_Loss: -0.462798 S_loss: 0.420986\n",
      "Train Epoch: 118 [20/50 (40%)]\tG_Loss: -0.423978 S_loss: 0.404957\n",
      "Train Epoch: 118 [30/50 (60%)]\tG_Loss: -0.426714 S_loss: 0.426758\n",
      "Train Epoch: 118 [40/50 (80%)]\tG_Loss: -0.435031 S_loss: 0.414008\n",
      "\n",
      "Test set: Average loss: 0.7248, Accuracy: 8310/10000 (83.1000%)\n",
      "\n",
      "Train Epoch: 119 [0/50 (0%)]\tG_Loss: -0.428835 S_loss: 0.417801\n",
      "Train Epoch: 119 [10/50 (20%)]\tG_Loss: -0.431395 S_loss: 0.431879\n",
      "Train Epoch: 119 [20/50 (40%)]\tG_Loss: -0.423394 S_loss: 0.408965\n",
      "Train Epoch: 119 [30/50 (60%)]\tG_Loss: -0.416775 S_loss: 0.446081\n",
      "Train Epoch: 119 [40/50 (80%)]\tG_Loss: -0.414021 S_loss: 0.409510\n",
      "\n",
      "Test set: Average loss: 0.7173, Accuracy: 8302/10000 (83.0200%)\n",
      "\n",
      "Train Epoch: 120 [0/50 (0%)]\tG_Loss: -0.434371 S_loss: 0.421001\n",
      "Train Epoch: 120 [10/50 (20%)]\tG_Loss: -0.428489 S_loss: 0.417491\n",
      "Train Epoch: 120 [20/50 (40%)]\tG_Loss: -0.435471 S_loss: 0.413522\n",
      "Train Epoch: 120 [30/50 (60%)]\tG_Loss: -0.426560 S_loss: 0.421070\n",
      "Train Epoch: 120 [40/50 (80%)]\tG_Loss: -0.422813 S_loss: 0.430186\n",
      "\n",
      "Test set: Average loss: 0.6987, Accuracy: 8329/10000 (83.2900%)\n",
      "\n",
      "Train Epoch: 121 [0/50 (0%)]\tG_Loss: -0.400838 S_loss: 0.419766\n",
      "Train Epoch: 121 [10/50 (20%)]\tG_Loss: -0.409685 S_loss: 0.416795\n",
      "Train Epoch: 121 [20/50 (40%)]\tG_Loss: -0.415275 S_loss: 0.401787\n",
      "Train Epoch: 121 [30/50 (60%)]\tG_Loss: -0.412909 S_loss: 0.408556\n",
      "Train Epoch: 121 [40/50 (80%)]\tG_Loss: -0.418993 S_loss: 0.418261\n",
      "\n",
      "Test set: Average loss: 0.7051, Accuracy: 8340/10000 (83.4000%)\n",
      "\n",
      "Train Epoch: 122 [0/50 (0%)]\tG_Loss: -0.415975 S_loss: 0.428235\n",
      "Train Epoch: 122 [10/50 (20%)]\tG_Loss: -0.410998 S_loss: 0.422001\n",
      "Train Epoch: 122 [20/50 (40%)]\tG_Loss: -0.428351 S_loss: 0.410063\n",
      "Train Epoch: 122 [30/50 (60%)]\tG_Loss: -0.420105 S_loss: 0.400809\n",
      "Train Epoch: 122 [40/50 (80%)]\tG_Loss: -0.430192 S_loss: 0.416162\n",
      "\n",
      "Test set: Average loss: 0.6983, Accuracy: 8361/10000 (83.6100%)\n",
      "\n",
      "Train Epoch: 123 [0/50 (0%)]\tG_Loss: -0.434292 S_loss: 0.423070\n",
      "Train Epoch: 123 [10/50 (20%)]\tG_Loss: -0.418360 S_loss: 0.415617\n",
      "Train Epoch: 123 [20/50 (40%)]\tG_Loss: -0.402289 S_loss: 0.396971\n",
      "Train Epoch: 123 [30/50 (60%)]\tG_Loss: -0.432760 S_loss: 0.418419\n",
      "Train Epoch: 123 [40/50 (80%)]\tG_Loss: -0.419517 S_loss: 0.417280\n",
      "\n",
      "Test set: Average loss: 0.6976, Accuracy: 8326/10000 (83.2600%)\n",
      "\n",
      "Train Epoch: 124 [0/50 (0%)]\tG_Loss: -0.436411 S_loss: 0.422211\n",
      "Train Epoch: 124 [10/50 (20%)]\tG_Loss: -0.415677 S_loss: 0.415305\n",
      "Train Epoch: 124 [20/50 (40%)]\tG_Loss: -0.429149 S_loss: 0.423456\n",
      "Train Epoch: 124 [30/50 (60%)]\tG_Loss: -0.411206 S_loss: 0.414213\n",
      "Train Epoch: 124 [40/50 (80%)]\tG_Loss: -0.425667 S_loss: 0.439291\n",
      "\n",
      "Test set: Average loss: 0.6691, Accuracy: 8435/10000 (84.3500%)\n",
      "\n",
      "Train Epoch: 125 [0/50 (0%)]\tG_Loss: -0.430145 S_loss: 0.420201\n",
      "Train Epoch: 125 [10/50 (20%)]\tG_Loss: -0.412176 S_loss: 0.420891\n",
      "Train Epoch: 125 [20/50 (40%)]\tG_Loss: -0.420270 S_loss: 0.398696\n",
      "Train Epoch: 125 [30/50 (60%)]\tG_Loss: -0.471290 S_loss: 0.410880\n",
      "Train Epoch: 125 [40/50 (80%)]\tG_Loss: -0.413126 S_loss: 0.418372\n",
      "\n",
      "Test set: Average loss: 0.6653, Accuracy: 8440/10000 (84.4000%)\n",
      "\n",
      "Train Epoch: 126 [0/50 (0%)]\tG_Loss: -0.425531 S_loss: 0.407547\n",
      "Train Epoch: 126 [10/50 (20%)]\tG_Loss: -0.444079 S_loss: 0.431394\n",
      "Train Epoch: 126 [20/50 (40%)]\tG_Loss: -0.411241 S_loss: 0.408324\n",
      "Train Epoch: 126 [30/50 (60%)]\tG_Loss: -0.430336 S_loss: 0.399647\n",
      "Train Epoch: 126 [40/50 (80%)]\tG_Loss: -0.416818 S_loss: 0.408341\n",
      "\n",
      "Test set: Average loss: 0.6459, Accuracy: 8470/10000 (84.7000%)\n",
      "\n",
      "Train Epoch: 127 [0/50 (0%)]\tG_Loss: -0.420499 S_loss: 0.428754\n",
      "Train Epoch: 127 [10/50 (20%)]\tG_Loss: -0.411057 S_loss: 0.410292\n",
      "Train Epoch: 127 [20/50 (40%)]\tG_Loss: -0.408445 S_loss: 0.408448\n",
      "Train Epoch: 127 [30/50 (60%)]\tG_Loss: -0.405838 S_loss: 0.411764\n",
      "Train Epoch: 127 [40/50 (80%)]\tG_Loss: -0.419104 S_loss: 0.411702\n",
      "\n",
      "Test set: Average loss: 0.6678, Accuracy: 8415/10000 (84.1500%)\n",
      "\n",
      "Train Epoch: 128 [0/50 (0%)]\tG_Loss: -0.432678 S_loss: 0.428046\n",
      "Train Epoch: 128 [10/50 (20%)]\tG_Loss: -0.449449 S_loss: 0.409064\n",
      "Train Epoch: 128 [20/50 (40%)]\tG_Loss: -0.432972 S_loss: 0.417254\n",
      "Train Epoch: 128 [30/50 (60%)]\tG_Loss: -0.415534 S_loss: 0.413896\n",
      "Train Epoch: 128 [40/50 (80%)]\tG_Loss: -0.413944 S_loss: 0.415232\n",
      "\n",
      "Test set: Average loss: 0.6843, Accuracy: 8374/10000 (83.7400%)\n",
      "\n",
      "Train Epoch: 129 [0/50 (0%)]\tG_Loss: -0.445421 S_loss: 0.416823\n",
      "Train Epoch: 129 [10/50 (20%)]\tG_Loss: -0.411599 S_loss: 0.421442\n",
      "Train Epoch: 129 [20/50 (40%)]\tG_Loss: -0.420534 S_loss: 0.413452\n",
      "Train Epoch: 129 [30/50 (60%)]\tG_Loss: -0.414416 S_loss: 0.425874\n",
      "Train Epoch: 129 [40/50 (80%)]\tG_Loss: -0.416347 S_loss: 0.397608\n",
      "\n",
      "Test set: Average loss: 0.6818, Accuracy: 8433/10000 (84.3300%)\n",
      "\n",
      "Train Epoch: 130 [0/50 (0%)]\tG_Loss: -0.433939 S_loss: 0.407707\n",
      "Train Epoch: 130 [10/50 (20%)]\tG_Loss: -0.411213 S_loss: 0.418877\n",
      "Train Epoch: 130 [20/50 (40%)]\tG_Loss: -0.409333 S_loss: 0.398964\n",
      "Train Epoch: 130 [30/50 (60%)]\tG_Loss: -0.410774 S_loss: 0.423707\n",
      "Train Epoch: 130 [40/50 (80%)]\tG_Loss: -0.396077 S_loss: 0.416028\n",
      "\n",
      "Test set: Average loss: 0.6670, Accuracy: 8436/10000 (84.3600%)\n",
      "\n",
      "Train Epoch: 131 [0/50 (0%)]\tG_Loss: -0.416796 S_loss: 0.413978\n",
      "Train Epoch: 131 [10/50 (20%)]\tG_Loss: -0.406093 S_loss: 0.398082\n",
      "Train Epoch: 131 [20/50 (40%)]\tG_Loss: -0.410693 S_loss: 0.410851\n",
      "Train Epoch: 131 [30/50 (60%)]\tG_Loss: -0.420770 S_loss: 0.400239\n",
      "Train Epoch: 131 [40/50 (80%)]\tG_Loss: -0.418813 S_loss: 0.399980\n",
      "\n",
      "Test set: Average loss: 0.6520, Accuracy: 8458/10000 (84.5800%)\n",
      "\n",
      "Train Epoch: 132 [0/50 (0%)]\tG_Loss: -0.412535 S_loss: 0.403957\n",
      "Train Epoch: 132 [10/50 (20%)]\tG_Loss: -0.398642 S_loss: 0.406872\n",
      "Train Epoch: 132 [20/50 (40%)]\tG_Loss: -0.411551 S_loss: 0.420521\n",
      "Train Epoch: 132 [30/50 (60%)]\tG_Loss: -0.410615 S_loss: 0.422772\n",
      "Train Epoch: 132 [40/50 (80%)]\tG_Loss: -0.419472 S_loss: 0.410167\n",
      "\n",
      "Test set: Average loss: 0.6444, Accuracy: 8472/10000 (84.7200%)\n",
      "\n",
      "Train Epoch: 133 [0/50 (0%)]\tG_Loss: -0.427126 S_loss: 0.420611\n",
      "Train Epoch: 133 [10/50 (20%)]\tG_Loss: -0.424513 S_loss: 0.399149\n",
      "Train Epoch: 133 [20/50 (40%)]\tG_Loss: -0.412785 S_loss: 0.408453\n",
      "Train Epoch: 133 [30/50 (60%)]\tG_Loss: -0.412859 S_loss: 0.395832\n",
      "Train Epoch: 133 [40/50 (80%)]\tG_Loss: -0.443745 S_loss: 0.402223\n",
      "\n",
      "Test set: Average loss: 0.6292, Accuracy: 8531/10000 (85.3100%)\n",
      "\n",
      "Train Epoch: 134 [0/50 (0%)]\tG_Loss: -0.424232 S_loss: 0.402814\n",
      "Train Epoch: 134 [10/50 (20%)]\tG_Loss: -0.412862 S_loss: 0.424764\n",
      "Train Epoch: 134 [20/50 (40%)]\tG_Loss: -0.425487 S_loss: 0.401680\n",
      "Train Epoch: 134 [30/50 (60%)]\tG_Loss: -0.421168 S_loss: 0.399383\n",
      "Train Epoch: 134 [40/50 (80%)]\tG_Loss: -0.407685 S_loss: 0.422462\n",
      "\n",
      "Test set: Average loss: 0.6277, Accuracy: 8494/10000 (84.9400%)\n",
      "\n",
      "Train Epoch: 135 [0/50 (0%)]\tG_Loss: -0.406471 S_loss: 0.402811\n",
      "Train Epoch: 135 [10/50 (20%)]\tG_Loss: -0.416476 S_loss: 0.407665\n",
      "Train Epoch: 135 [20/50 (40%)]\tG_Loss: -0.421627 S_loss: 0.407948\n",
      "Train Epoch: 135 [30/50 (60%)]\tG_Loss: -0.425405 S_loss: 0.418141\n",
      "Train Epoch: 135 [40/50 (80%)]\tG_Loss: -0.425859 S_loss: 0.403649\n",
      "\n",
      "Test set: Average loss: 0.6868, Accuracy: 8399/10000 (83.9900%)\n",
      "\n",
      "Train Epoch: 136 [0/50 (0%)]\tG_Loss: -0.423216 S_loss: 0.422297\n",
      "Train Epoch: 136 [10/50 (20%)]\tG_Loss: -0.422615 S_loss: 0.412385\n",
      "Train Epoch: 136 [20/50 (40%)]\tG_Loss: -0.425906 S_loss: 0.409536\n",
      "Train Epoch: 136 [30/50 (60%)]\tG_Loss: -0.430513 S_loss: 0.404599\n",
      "Train Epoch: 136 [40/50 (80%)]\tG_Loss: -0.433470 S_loss: 0.401116\n",
      "\n",
      "Test set: Average loss: 0.6647, Accuracy: 8445/10000 (84.4500%)\n",
      "\n",
      "Train Epoch: 137 [0/50 (0%)]\tG_Loss: -0.428538 S_loss: 0.418666\n",
      "Train Epoch: 137 [10/50 (20%)]\tG_Loss: -0.435450 S_loss: 0.414523\n",
      "Train Epoch: 137 [20/50 (40%)]\tG_Loss: -0.414302 S_loss: 0.399468\n",
      "Train Epoch: 137 [30/50 (60%)]\tG_Loss: -0.413590 S_loss: 0.415272\n",
      "Train Epoch: 137 [40/50 (80%)]\tG_Loss: -0.435724 S_loss: 0.424382\n",
      "\n",
      "Test set: Average loss: 0.6274, Accuracy: 8506/10000 (85.0600%)\n",
      "\n",
      "Train Epoch: 138 [0/50 (0%)]\tG_Loss: -0.418179 S_loss: 0.407840\n",
      "Train Epoch: 138 [10/50 (20%)]\tG_Loss: -0.418589 S_loss: 0.407251\n",
      "Train Epoch: 138 [20/50 (40%)]\tG_Loss: -0.403994 S_loss: 0.419316\n",
      "Train Epoch: 138 [30/50 (60%)]\tG_Loss: -0.419970 S_loss: 0.401463\n",
      "Train Epoch: 138 [40/50 (80%)]\tG_Loss: -0.426257 S_loss: 0.413834\n",
      "\n",
      "Test set: Average loss: 0.6573, Accuracy: 8463/10000 (84.6300%)\n",
      "\n",
      "Train Epoch: 139 [0/50 (0%)]\tG_Loss: -0.458049 S_loss: 0.408772\n",
      "Train Epoch: 139 [10/50 (20%)]\tG_Loss: -0.436705 S_loss: 0.412224\n",
      "Train Epoch: 139 [20/50 (40%)]\tG_Loss: -0.411769 S_loss: 0.418460\n",
      "Train Epoch: 139 [30/50 (60%)]\tG_Loss: -0.425230 S_loss: 0.402144\n",
      "Train Epoch: 139 [40/50 (80%)]\tG_Loss: -0.414272 S_loss: 0.408312\n",
      "\n",
      "Test set: Average loss: 0.6733, Accuracy: 8492/10000 (84.9200%)\n",
      "\n",
      "Train Epoch: 140 [0/50 (0%)]\tG_Loss: -0.409153 S_loss: 0.419407\n",
      "Train Epoch: 140 [10/50 (20%)]\tG_Loss: -0.398214 S_loss: 0.407552\n",
      "Train Epoch: 140 [20/50 (40%)]\tG_Loss: -0.415689 S_loss: 0.418969\n",
      "Train Epoch: 140 [30/50 (60%)]\tG_Loss: -0.403233 S_loss: 0.383528\n",
      "Train Epoch: 140 [40/50 (80%)]\tG_Loss: -0.412030 S_loss: 0.392581\n",
      "\n",
      "Test set: Average loss: 0.6400, Accuracy: 8506/10000 (85.0600%)\n",
      "\n",
      "Train Epoch: 141 [0/50 (0%)]\tG_Loss: -0.422754 S_loss: 0.401958\n",
      "Train Epoch: 141 [10/50 (20%)]\tG_Loss: -0.421282 S_loss: 0.410034\n",
      "Train Epoch: 141 [20/50 (40%)]\tG_Loss: -0.405542 S_loss: 0.408932\n",
      "Train Epoch: 141 [30/50 (60%)]\tG_Loss: -0.402739 S_loss: 0.395318\n",
      "Train Epoch: 141 [40/50 (80%)]\tG_Loss: -0.422660 S_loss: 0.403611\n",
      "\n",
      "Test set: Average loss: 0.6358, Accuracy: 8510/10000 (85.1000%)\n",
      "\n",
      "Train Epoch: 142 [0/50 (0%)]\tG_Loss: -0.405022 S_loss: 0.390963\n",
      "Train Epoch: 142 [10/50 (20%)]\tG_Loss: -0.409345 S_loss: 0.412872\n",
      "Train Epoch: 142 [20/50 (40%)]\tG_Loss: -0.416672 S_loss: 0.418116\n",
      "Train Epoch: 142 [30/50 (60%)]\tG_Loss: -0.418509 S_loss: 0.415037\n",
      "Train Epoch: 142 [40/50 (80%)]\tG_Loss: -0.427351 S_loss: 0.424117\n",
      "\n",
      "Test set: Average loss: 0.6382, Accuracy: 8520/10000 (85.2000%)\n",
      "\n",
      "Train Epoch: 143 [0/50 (0%)]\tG_Loss: -0.421343 S_loss: 0.423017\n",
      "Train Epoch: 143 [10/50 (20%)]\tG_Loss: -0.429031 S_loss: 0.410410\n",
      "Train Epoch: 143 [20/50 (40%)]\tG_Loss: -0.436074 S_loss: 0.413176\n",
      "Train Epoch: 143 [30/50 (60%)]\tG_Loss: -0.401574 S_loss: 0.402931\n",
      "Train Epoch: 143 [40/50 (80%)]\tG_Loss: -0.409241 S_loss: 0.414235\n",
      "\n",
      "Test set: Average loss: 0.6440, Accuracy: 8506/10000 (85.0600%)\n",
      "\n",
      "Train Epoch: 144 [0/50 (0%)]\tG_Loss: -0.413976 S_loss: 0.415645\n",
      "Train Epoch: 144 [10/50 (20%)]\tG_Loss: -0.409989 S_loss: 0.403686\n",
      "Train Epoch: 144 [20/50 (40%)]\tG_Loss: -0.415661 S_loss: 0.409751\n",
      "Train Epoch: 144 [30/50 (60%)]\tG_Loss: -0.428473 S_loss: 0.400497\n",
      "Train Epoch: 144 [40/50 (80%)]\tG_Loss: -0.393250 S_loss: 0.406662\n",
      "\n",
      "Test set: Average loss: 0.6182, Accuracy: 8558/10000 (85.5800%)\n",
      "\n",
      "Train Epoch: 145 [0/50 (0%)]\tG_Loss: -0.408214 S_loss: 0.403928\n",
      "Train Epoch: 145 [10/50 (20%)]\tG_Loss: -0.397486 S_loss: 0.410062\n",
      "Train Epoch: 145 [20/50 (40%)]\tG_Loss: -0.412398 S_loss: 0.419425\n",
      "Train Epoch: 145 [30/50 (60%)]\tG_Loss: -0.416066 S_loss: 0.410187\n",
      "Train Epoch: 145 [40/50 (80%)]\tG_Loss: -0.404684 S_loss: 0.403146\n",
      "\n",
      "Test set: Average loss: 0.6318, Accuracy: 8537/10000 (85.3700%)\n",
      "\n",
      "Train Epoch: 146 [0/50 (0%)]\tG_Loss: -0.414877 S_loss: 0.405412\n",
      "Train Epoch: 146 [10/50 (20%)]\tG_Loss: -0.403689 S_loss: 0.416562\n",
      "Train Epoch: 146 [20/50 (40%)]\tG_Loss: -0.423662 S_loss: 0.392501\n",
      "Train Epoch: 146 [30/50 (60%)]\tG_Loss: -0.407132 S_loss: 0.403081\n",
      "Train Epoch: 146 [40/50 (80%)]\tG_Loss: -0.419258 S_loss: 0.419012\n",
      "\n",
      "Test set: Average loss: 0.6380, Accuracy: 8501/10000 (85.0100%)\n",
      "\n",
      "Train Epoch: 147 [0/50 (0%)]\tG_Loss: -0.406692 S_loss: 0.398175\n",
      "Train Epoch: 147 [10/50 (20%)]\tG_Loss: -0.434974 S_loss: 0.405794\n",
      "Train Epoch: 147 [20/50 (40%)]\tG_Loss: -0.418845 S_loss: 0.401340\n",
      "Train Epoch: 147 [30/50 (60%)]\tG_Loss: -0.403930 S_loss: 0.406630\n",
      "Train Epoch: 147 [40/50 (80%)]\tG_Loss: -0.396522 S_loss: 0.404843\n",
      "\n",
      "Test set: Average loss: 0.6373, Accuracy: 8529/10000 (85.2900%)\n",
      "\n",
      "Train Epoch: 148 [0/50 (0%)]\tG_Loss: -0.414985 S_loss: 0.385765\n",
      "Train Epoch: 148 [10/50 (20%)]\tG_Loss: -0.415846 S_loss: 0.407839\n",
      "Train Epoch: 148 [20/50 (40%)]\tG_Loss: -0.441805 S_loss: 0.402943\n",
      "Train Epoch: 148 [30/50 (60%)]\tG_Loss: -0.406571 S_loss: 0.397446\n",
      "Train Epoch: 148 [40/50 (80%)]\tG_Loss: -0.407293 S_loss: 0.394990\n",
      "\n",
      "Test set: Average loss: 0.6297, Accuracy: 8507/10000 (85.0700%)\n",
      "\n",
      "Train Epoch: 149 [0/50 (0%)]\tG_Loss: -0.422714 S_loss: 0.394439\n",
      "Train Epoch: 149 [10/50 (20%)]\tG_Loss: -0.402077 S_loss: 0.415548\n",
      "Train Epoch: 149 [20/50 (40%)]\tG_Loss: -0.443589 S_loss: 0.400068\n",
      "Train Epoch: 149 [30/50 (60%)]\tG_Loss: -0.425761 S_loss: 0.406715\n",
      "Train Epoch: 149 [40/50 (80%)]\tG_Loss: -0.422871 S_loss: 0.404411\n",
      "\n",
      "Test set: Average loss: 0.6375, Accuracy: 8511/10000 (85.1100%)\n",
      "\n",
      "Train Epoch: 150 [0/50 (0%)]\tG_Loss: -0.417051 S_loss: 0.416531\n",
      "Train Epoch: 150 [10/50 (20%)]\tG_Loss: -0.413070 S_loss: 0.403087\n",
      "Train Epoch: 150 [20/50 (40%)]\tG_Loss: -0.434080 S_loss: 0.424629\n",
      "Train Epoch: 150 [30/50 (60%)]\tG_Loss: -0.400110 S_loss: 0.421680\n",
      "Train Epoch: 150 [40/50 (80%)]\tG_Loss: -0.405279 S_loss: 0.391057\n",
      "\n",
      "Test set: Average loss: 0.6564, Accuracy: 8472/10000 (84.7200%)\n",
      "\n",
      "Train Epoch: 151 [0/50 (0%)]\tG_Loss: -0.425786 S_loss: 0.410418\n",
      "Train Epoch: 151 [10/50 (20%)]\tG_Loss: -0.405373 S_loss: 0.405402\n",
      "Train Epoch: 151 [20/50 (40%)]\tG_Loss: -0.434361 S_loss: 0.412600\n",
      "Train Epoch: 151 [30/50 (60%)]\tG_Loss: -0.391365 S_loss: 0.408218\n",
      "Train Epoch: 151 [40/50 (80%)]\tG_Loss: -0.400655 S_loss: 0.396553\n",
      "\n",
      "Test set: Average loss: 0.6411, Accuracy: 8487/10000 (84.8700%)\n",
      "\n",
      "Train Epoch: 152 [0/50 (0%)]\tG_Loss: -0.442670 S_loss: 0.406204\n",
      "Train Epoch: 152 [10/50 (20%)]\tG_Loss: -0.406272 S_loss: 0.405633\n",
      "Train Epoch: 152 [20/50 (40%)]\tG_Loss: -0.421824 S_loss: 0.406162\n",
      "Train Epoch: 152 [30/50 (60%)]\tG_Loss: -0.390548 S_loss: 0.396303\n",
      "Train Epoch: 152 [40/50 (80%)]\tG_Loss: -0.412959 S_loss: 0.392797\n",
      "\n",
      "Test set: Average loss: 0.5969, Accuracy: 8605/10000 (86.0500%)\n",
      "\n",
      "Train Epoch: 153 [0/50 (0%)]\tG_Loss: -0.427409 S_loss: 0.404266\n",
      "Train Epoch: 153 [10/50 (20%)]\tG_Loss: -0.410991 S_loss: 0.403558\n",
      "Train Epoch: 153 [20/50 (40%)]\tG_Loss: -0.402386 S_loss: 0.404477\n",
      "Train Epoch: 153 [30/50 (60%)]\tG_Loss: -0.402081 S_loss: 0.413506\n",
      "Train Epoch: 153 [40/50 (80%)]\tG_Loss: -0.409507 S_loss: 0.391970\n",
      "\n",
      "Test set: Average loss: 0.6197, Accuracy: 8566/10000 (85.6600%)\n",
      "\n",
      "Train Epoch: 154 [0/50 (0%)]\tG_Loss: -0.408678 S_loss: 0.394134\n",
      "Train Epoch: 154 [10/50 (20%)]\tG_Loss: -0.403454 S_loss: 0.408170\n",
      "Train Epoch: 154 [20/50 (40%)]\tG_Loss: -0.424039 S_loss: 0.391572\n",
      "Train Epoch: 154 [30/50 (60%)]\tG_Loss: -0.434640 S_loss: 0.407749\n",
      "Train Epoch: 154 [40/50 (80%)]\tG_Loss: -0.396889 S_loss: 0.401602\n",
      "\n",
      "Test set: Average loss: 0.6153, Accuracy: 8560/10000 (85.6000%)\n",
      "\n",
      "Train Epoch: 155 [0/50 (0%)]\tG_Loss: -0.397656 S_loss: 0.401652\n",
      "Train Epoch: 155 [10/50 (20%)]\tG_Loss: -0.416586 S_loss: 0.391519\n",
      "Train Epoch: 155 [20/50 (40%)]\tG_Loss: -0.430132 S_loss: 0.393169\n",
      "Train Epoch: 155 [30/50 (60%)]\tG_Loss: -0.412975 S_loss: 0.403674\n",
      "Train Epoch: 155 [40/50 (80%)]\tG_Loss: -0.460517 S_loss: 0.389174\n",
      "\n",
      "Test set: Average loss: 0.6485, Accuracy: 8467/10000 (84.6700%)\n",
      "\n",
      "Train Epoch: 156 [0/50 (0%)]\tG_Loss: -0.423864 S_loss: 0.406279\n",
      "Train Epoch: 156 [10/50 (20%)]\tG_Loss: -0.422648 S_loss: 0.422105\n",
      "Train Epoch: 156 [20/50 (40%)]\tG_Loss: -0.407596 S_loss: 0.412389\n",
      "Train Epoch: 156 [30/50 (60%)]\tG_Loss: -0.423485 S_loss: 0.397594\n",
      "Train Epoch: 156 [40/50 (80%)]\tG_Loss: -0.426655 S_loss: 0.407070\n",
      "\n",
      "Test set: Average loss: 0.6246, Accuracy: 8540/10000 (85.4000%)\n",
      "\n",
      "Train Epoch: 157 [0/50 (0%)]\tG_Loss: -0.431802 S_loss: 0.425044\n",
      "Train Epoch: 157 [10/50 (20%)]\tG_Loss: -0.407362 S_loss: 0.412933\n",
      "Train Epoch: 157 [20/50 (40%)]\tG_Loss: -0.397487 S_loss: 0.399826\n",
      "Train Epoch: 157 [30/50 (60%)]\tG_Loss: -0.408967 S_loss: 0.404396\n",
      "Train Epoch: 157 [40/50 (80%)]\tG_Loss: -0.444890 S_loss: 0.393557\n",
      "\n",
      "Test set: Average loss: 0.6430, Accuracy: 8484/10000 (84.8400%)\n",
      "\n",
      "Train Epoch: 158 [0/50 (0%)]\tG_Loss: -0.411576 S_loss: 0.413056\n",
      "Train Epoch: 158 [10/50 (20%)]\tG_Loss: -0.405820 S_loss: 0.407664\n",
      "Train Epoch: 158 [20/50 (40%)]\tG_Loss: -0.408564 S_loss: 0.406305\n",
      "Train Epoch: 158 [30/50 (60%)]\tG_Loss: -0.431257 S_loss: 0.412243\n",
      "Train Epoch: 158 [40/50 (80%)]\tG_Loss: -0.420538 S_loss: 0.390413\n",
      "\n",
      "Test set: Average loss: 0.6252, Accuracy: 8561/10000 (85.6100%)\n",
      "\n",
      "Train Epoch: 159 [0/50 (0%)]\tG_Loss: -0.407367 S_loss: 0.384975\n",
      "Train Epoch: 159 [10/50 (20%)]\tG_Loss: -0.411247 S_loss: 0.396912\n",
      "Train Epoch: 159 [20/50 (40%)]\tG_Loss: -0.431936 S_loss: 0.394122\n",
      "Train Epoch: 159 [30/50 (60%)]\tG_Loss: -0.435539 S_loss: 0.397289\n",
      "Train Epoch: 159 [40/50 (80%)]\tG_Loss: -0.406614 S_loss: 0.409875\n",
      "\n",
      "Test set: Average loss: 0.6273, Accuracy: 8554/10000 (85.5400%)\n",
      "\n",
      "Train Epoch: 160 [0/50 (0%)]\tG_Loss: -0.420770 S_loss: 0.415749\n",
      "Train Epoch: 160 [10/50 (20%)]\tG_Loss: -0.417124 S_loss: 0.401227\n",
      "Train Epoch: 160 [20/50 (40%)]\tG_Loss: -0.393600 S_loss: 0.408156\n",
      "Train Epoch: 160 [30/50 (60%)]\tG_Loss: -0.405402 S_loss: 0.396151\n",
      "Train Epoch: 160 [40/50 (80%)]\tG_Loss: -0.405900 S_loss: 0.413441\n",
      "\n",
      "Test set: Average loss: 0.6046, Accuracy: 8603/10000 (86.0300%)\n",
      "\n",
      "Train Epoch: 161 [0/50 (0%)]\tG_Loss: -0.411040 S_loss: 0.413251\n",
      "Train Epoch: 161 [10/50 (20%)]\tG_Loss: -0.401899 S_loss: 0.392024\n",
      "Train Epoch: 161 [20/50 (40%)]\tG_Loss: -0.407929 S_loss: 0.404989\n",
      "Train Epoch: 161 [30/50 (60%)]\tG_Loss: -0.413184 S_loss: 0.403128\n",
      "Train Epoch: 161 [40/50 (80%)]\tG_Loss: -0.413462 S_loss: 0.393367\n",
      "\n",
      "Test set: Average loss: 0.5987, Accuracy: 8618/10000 (86.1800%)\n",
      "\n",
      "Train Epoch: 162 [0/50 (0%)]\tG_Loss: -0.399502 S_loss: 0.388296\n",
      "Train Epoch: 162 [10/50 (20%)]\tG_Loss: -0.402029 S_loss: 0.394963\n",
      "Train Epoch: 162 [20/50 (40%)]\tG_Loss: -0.411993 S_loss: 0.406668\n",
      "Train Epoch: 162 [30/50 (60%)]\tG_Loss: -0.458287 S_loss: 0.405008\n",
      "Train Epoch: 162 [40/50 (80%)]\tG_Loss: -0.411250 S_loss: 0.395541\n",
      "\n",
      "Test set: Average loss: 0.6129, Accuracy: 8613/10000 (86.1300%)\n",
      "\n",
      "Train Epoch: 163 [0/50 (0%)]\tG_Loss: -0.397361 S_loss: 0.409902\n",
      "Train Epoch: 163 [10/50 (20%)]\tG_Loss: -0.417188 S_loss: 0.413121\n",
      "Train Epoch: 163 [20/50 (40%)]\tG_Loss: -0.399242 S_loss: 0.411787\n",
      "Train Epoch: 163 [30/50 (60%)]\tG_Loss: -0.413713 S_loss: 0.404968\n",
      "Train Epoch: 163 [40/50 (80%)]\tG_Loss: -0.404460 S_loss: 0.409642\n",
      "\n",
      "Test set: Average loss: 0.6340, Accuracy: 8522/10000 (85.2200%)\n",
      "\n",
      "Train Epoch: 164 [0/50 (0%)]\tG_Loss: -0.410331 S_loss: 0.401920\n",
      "Train Epoch: 164 [10/50 (20%)]\tG_Loss: -0.412779 S_loss: 0.404244\n",
      "Train Epoch: 164 [20/50 (40%)]\tG_Loss: -0.405875 S_loss: 0.390333\n",
      "Train Epoch: 164 [30/50 (60%)]\tG_Loss: -0.407171 S_loss: 0.405193\n",
      "Train Epoch: 164 [40/50 (80%)]\tG_Loss: -0.395944 S_loss: 0.404489\n",
      "\n",
      "Test set: Average loss: 0.6490, Accuracy: 8516/10000 (85.1600%)\n",
      "\n",
      "Train Epoch: 165 [0/50 (0%)]\tG_Loss: -0.387412 S_loss: 0.396738\n",
      "Train Epoch: 165 [10/50 (20%)]\tG_Loss: -0.389761 S_loss: 0.395344\n",
      "Train Epoch: 165 [20/50 (40%)]\tG_Loss: -0.394279 S_loss: 0.400351\n",
      "Train Epoch: 165 [30/50 (60%)]\tG_Loss: -0.414938 S_loss: 0.410021\n",
      "Train Epoch: 165 [40/50 (80%)]\tG_Loss: -0.401330 S_loss: 0.393357\n",
      "\n",
      "Test set: Average loss: 0.6450, Accuracy: 8470/10000 (84.7000%)\n",
      "\n",
      "Train Epoch: 166 [0/50 (0%)]\tG_Loss: -0.397055 S_loss: 0.406219\n",
      "Train Epoch: 166 [10/50 (20%)]\tG_Loss: -0.422683 S_loss: 0.407247\n",
      "Train Epoch: 166 [20/50 (40%)]\tG_Loss: -0.411006 S_loss: 0.401340\n",
      "Train Epoch: 166 [30/50 (60%)]\tG_Loss: -0.430064 S_loss: 0.412535\n",
      "Train Epoch: 166 [40/50 (80%)]\tG_Loss: -0.418476 S_loss: 0.420083\n",
      "\n",
      "Test set: Average loss: 0.5965, Accuracy: 8594/10000 (85.9400%)\n",
      "\n",
      "Train Epoch: 167 [0/50 (0%)]\tG_Loss: -0.418463 S_loss: 0.407309\n",
      "Train Epoch: 167 [10/50 (20%)]\tG_Loss: -0.421406 S_loss: 0.389612\n",
      "Train Epoch: 167 [20/50 (40%)]\tG_Loss: -0.404022 S_loss: 0.408314\n",
      "Train Epoch: 167 [30/50 (60%)]\tG_Loss: -0.398186 S_loss: 0.412807\n",
      "Train Epoch: 167 [40/50 (80%)]\tG_Loss: -0.415695 S_loss: 0.395004\n",
      "\n",
      "Test set: Average loss: 0.6161, Accuracy: 8583/10000 (85.8300%)\n",
      "\n",
      "Train Epoch: 168 [0/50 (0%)]\tG_Loss: -0.414784 S_loss: 0.401456\n",
      "Train Epoch: 168 [10/50 (20%)]\tG_Loss: -0.405158 S_loss: 0.390124\n",
      "Train Epoch: 168 [20/50 (40%)]\tG_Loss: -0.417572 S_loss: 0.405410\n",
      "Train Epoch: 168 [30/50 (60%)]\tG_Loss: -0.409778 S_loss: 0.412712\n",
      "Train Epoch: 168 [40/50 (80%)]\tG_Loss: -0.405678 S_loss: 0.418478\n",
      "\n",
      "Test set: Average loss: 0.6462, Accuracy: 8521/10000 (85.2100%)\n",
      "\n",
      "Train Epoch: 169 [0/50 (0%)]\tG_Loss: -0.416123 S_loss: 0.411661\n",
      "Train Epoch: 169 [10/50 (20%)]\tG_Loss: -0.414327 S_loss: 0.406727\n",
      "Train Epoch: 169 [20/50 (40%)]\tG_Loss: -0.408848 S_loss: 0.398233\n",
      "Train Epoch: 169 [30/50 (60%)]\tG_Loss: -0.408236 S_loss: 0.390629\n",
      "Train Epoch: 169 [40/50 (80%)]\tG_Loss: -0.406954 S_loss: 0.387868\n",
      "\n",
      "Test set: Average loss: 0.6136, Accuracy: 8580/10000 (85.8000%)\n",
      "\n",
      "Train Epoch: 170 [0/50 (0%)]\tG_Loss: -0.408568 S_loss: 0.393455\n",
      "Train Epoch: 170 [10/50 (20%)]\tG_Loss: -0.427618 S_loss: 0.397664\n",
      "Train Epoch: 170 [20/50 (40%)]\tG_Loss: -0.420326 S_loss: 0.414977\n",
      "Train Epoch: 170 [30/50 (60%)]\tG_Loss: -0.410493 S_loss: 0.402427\n",
      "Train Epoch: 170 [40/50 (80%)]\tG_Loss: -0.409375 S_loss: 0.401805\n",
      "\n",
      "Test set: Average loss: 0.5928, Accuracy: 8611/10000 (86.1100%)\n",
      "\n",
      "Train Epoch: 171 [0/50 (0%)]\tG_Loss: -0.396201 S_loss: 0.414564\n",
      "Train Epoch: 171 [10/50 (20%)]\tG_Loss: -0.394261 S_loss: 0.417122\n",
      "Train Epoch: 171 [20/50 (40%)]\tG_Loss: -0.419192 S_loss: 0.411918\n",
      "Train Epoch: 171 [30/50 (60%)]\tG_Loss: -0.417200 S_loss: 0.408721\n",
      "Train Epoch: 171 [40/50 (80%)]\tG_Loss: -0.411024 S_loss: 0.404728\n",
      "\n",
      "Test set: Average loss: 0.6038, Accuracy: 8621/10000 (86.2100%)\n",
      "\n",
      "Train Epoch: 172 [0/50 (0%)]\tG_Loss: -0.407378 S_loss: 0.395607\n",
      "Train Epoch: 172 [10/50 (20%)]\tG_Loss: -0.407940 S_loss: 0.399690\n",
      "Train Epoch: 172 [20/50 (40%)]\tG_Loss: -0.425283 S_loss: 0.402219\n",
      "Train Epoch: 172 [30/50 (60%)]\tG_Loss: -0.425381 S_loss: 0.377414\n",
      "Train Epoch: 172 [40/50 (80%)]\tG_Loss: -0.386253 S_loss: 0.402163\n",
      "\n",
      "Test set: Average loss: 0.6159, Accuracy: 8591/10000 (85.9100%)\n",
      "\n",
      "Train Epoch: 173 [0/50 (0%)]\tG_Loss: -0.424196 S_loss: 0.402184\n",
      "Train Epoch: 173 [10/50 (20%)]\tG_Loss: -0.428056 S_loss: 0.393277\n",
      "Train Epoch: 173 [20/50 (40%)]\tG_Loss: -0.416066 S_loss: 0.412167\n",
      "Train Epoch: 173 [30/50 (60%)]\tG_Loss: -0.417212 S_loss: 0.394853\n",
      "Train Epoch: 173 [40/50 (80%)]\tG_Loss: -0.425185 S_loss: 0.406110\n",
      "\n",
      "Test set: Average loss: 0.5859, Accuracy: 8644/10000 (86.4400%)\n",
      "\n",
      "Train Epoch: 174 [0/50 (0%)]\tG_Loss: -0.403538 S_loss: 0.417340\n",
      "Train Epoch: 174 [10/50 (20%)]\tG_Loss: -0.392841 S_loss: 0.391844\n",
      "Train Epoch: 174 [20/50 (40%)]\tG_Loss: -0.417408 S_loss: 0.405824\n",
      "Train Epoch: 174 [30/50 (60%)]\tG_Loss: -0.391275 S_loss: 0.390755\n",
      "Train Epoch: 174 [40/50 (80%)]\tG_Loss: -0.422624 S_loss: 0.395586\n",
      "\n",
      "Test set: Average loss: 0.6420, Accuracy: 8496/10000 (84.9600%)\n",
      "\n",
      "Train Epoch: 175 [0/50 (0%)]\tG_Loss: -0.399155 S_loss: 0.403094\n",
      "Train Epoch: 175 [10/50 (20%)]\tG_Loss: -0.413694 S_loss: 0.402390\n",
      "Train Epoch: 175 [20/50 (40%)]\tG_Loss: -0.419393 S_loss: 0.395526\n",
      "Train Epoch: 175 [30/50 (60%)]\tG_Loss: -0.407979 S_loss: 0.394759\n",
      "Train Epoch: 175 [40/50 (80%)]\tG_Loss: -0.422511 S_loss: 0.410479\n",
      "\n",
      "Test set: Average loss: 0.6089, Accuracy: 8580/10000 (85.8000%)\n",
      "\n",
      "Train Epoch: 176 [0/50 (0%)]\tG_Loss: -0.436817 S_loss: 0.427182\n",
      "Train Epoch: 176 [10/50 (20%)]\tG_Loss: -0.447520 S_loss: 0.404652\n",
      "Train Epoch: 176 [20/50 (40%)]\tG_Loss: -0.418816 S_loss: 0.399689\n",
      "Train Epoch: 176 [30/50 (60%)]\tG_Loss: -0.430405 S_loss: 0.405186\n",
      "Train Epoch: 176 [40/50 (80%)]\tG_Loss: -0.410240 S_loss: 0.406697\n",
      "\n",
      "Test set: Average loss: 0.6063, Accuracy: 8567/10000 (85.6700%)\n",
      "\n",
      "Train Epoch: 177 [0/50 (0%)]\tG_Loss: -0.445698 S_loss: 0.410086\n",
      "Train Epoch: 177 [10/50 (20%)]\tG_Loss: -0.411402 S_loss: 0.396769\n",
      "Train Epoch: 177 [20/50 (40%)]\tG_Loss: -0.393778 S_loss: 0.412217\n",
      "Train Epoch: 177 [30/50 (60%)]\tG_Loss: -0.410841 S_loss: 0.398257\n",
      "Train Epoch: 177 [40/50 (80%)]\tG_Loss: -0.408932 S_loss: 0.400064\n",
      "\n",
      "Test set: Average loss: 0.6045, Accuracy: 8587/10000 (85.8700%)\n",
      "\n",
      "Train Epoch: 178 [0/50 (0%)]\tG_Loss: -0.413138 S_loss: 0.393766\n",
      "Train Epoch: 178 [10/50 (20%)]\tG_Loss: -0.403901 S_loss: 0.392513\n",
      "Train Epoch: 178 [20/50 (40%)]\tG_Loss: -0.416273 S_loss: 0.394516\n",
      "Train Epoch: 178 [30/50 (60%)]\tG_Loss: -0.405886 S_loss: 0.398861\n",
      "Train Epoch: 178 [40/50 (80%)]\tG_Loss: -0.404892 S_loss: 0.398643\n",
      "\n",
      "Test set: Average loss: 0.6037, Accuracy: 8629/10000 (86.2900%)\n",
      "\n",
      "Train Epoch: 179 [0/50 (0%)]\tG_Loss: -0.406444 S_loss: 0.403758\n",
      "Train Epoch: 179 [10/50 (20%)]\tG_Loss: -0.413491 S_loss: 0.379939\n",
      "Train Epoch: 179 [20/50 (40%)]\tG_Loss: -0.413498 S_loss: 0.386305\n",
      "Train Epoch: 179 [30/50 (60%)]\tG_Loss: -0.410092 S_loss: 0.410128\n",
      "Train Epoch: 179 [40/50 (80%)]\tG_Loss: -0.398004 S_loss: 0.397847\n",
      "\n",
      "Test set: Average loss: 0.6025, Accuracy: 8619/10000 (86.1900%)\n",
      "\n",
      "Train Epoch: 180 [0/50 (0%)]\tG_Loss: -0.400859 S_loss: 0.384208\n",
      "Train Epoch: 180 [10/50 (20%)]\tG_Loss: -0.411858 S_loss: 0.415861\n",
      "Train Epoch: 180 [20/50 (40%)]\tG_Loss: -0.416195 S_loss: 0.396728\n",
      "Train Epoch: 180 [30/50 (60%)]\tG_Loss: -0.405469 S_loss: 0.396600\n",
      "Train Epoch: 180 [40/50 (80%)]\tG_Loss: -0.453154 S_loss: 0.404544\n",
      "\n",
      "Test set: Average loss: 0.6126, Accuracy: 8601/10000 (86.0100%)\n",
      "\n",
      "Train Epoch: 181 [0/50 (0%)]\tG_Loss: -0.434253 S_loss: 0.401996\n",
      "Train Epoch: 181 [10/50 (20%)]\tG_Loss: -0.408557 S_loss: 0.396329\n",
      "Train Epoch: 181 [20/50 (40%)]\tG_Loss: -0.397141 S_loss: 0.403482\n",
      "Train Epoch: 181 [30/50 (60%)]\tG_Loss: -0.404656 S_loss: 0.400684\n",
      "Train Epoch: 181 [40/50 (80%)]\tG_Loss: -0.405859 S_loss: 0.409936\n",
      "\n",
      "Test set: Average loss: 0.5823, Accuracy: 8647/10000 (86.4700%)\n",
      "\n",
      "Train Epoch: 182 [0/50 (0%)]\tG_Loss: -0.397966 S_loss: 0.397422\n",
      "Train Epoch: 182 [10/50 (20%)]\tG_Loss: -0.403682 S_loss: 0.399507\n",
      "Train Epoch: 182 [20/50 (40%)]\tG_Loss: -0.418067 S_loss: 0.381496\n",
      "Train Epoch: 182 [30/50 (60%)]\tG_Loss: -0.389604 S_loss: 0.388246\n",
      "Train Epoch: 182 [40/50 (80%)]\tG_Loss: -0.421154 S_loss: 0.404634\n",
      "\n",
      "Test set: Average loss: 0.6206, Accuracy: 8579/10000 (85.7900%)\n",
      "\n",
      "Train Epoch: 183 [0/50 (0%)]\tG_Loss: -0.416192 S_loss: 0.392389\n",
      "Train Epoch: 183 [10/50 (20%)]\tG_Loss: -0.418832 S_loss: 0.394942\n",
      "Train Epoch: 183 [20/50 (40%)]\tG_Loss: -0.424945 S_loss: 0.391821\n",
      "Train Epoch: 183 [30/50 (60%)]\tG_Loss: -0.441969 S_loss: 0.404241\n",
      "Train Epoch: 183 [40/50 (80%)]\tG_Loss: -0.400581 S_loss: 0.391801\n",
      "\n",
      "Test set: Average loss: 0.6098, Accuracy: 8604/10000 (86.0400%)\n",
      "\n",
      "Train Epoch: 184 [0/50 (0%)]\tG_Loss: -0.440218 S_loss: 0.399229\n",
      "Train Epoch: 184 [10/50 (20%)]\tG_Loss: -0.429853 S_loss: 0.397172\n",
      "Train Epoch: 184 [20/50 (40%)]\tG_Loss: -0.409505 S_loss: 0.413306\n",
      "Train Epoch: 184 [30/50 (60%)]\tG_Loss: -0.409090 S_loss: 0.400390\n",
      "Train Epoch: 184 [40/50 (80%)]\tG_Loss: -0.435465 S_loss: 0.390875\n",
      "\n",
      "Test set: Average loss: 0.6009, Accuracy: 8582/10000 (85.8200%)\n",
      "\n",
      "Train Epoch: 185 [0/50 (0%)]\tG_Loss: -0.399329 S_loss: 0.393927\n",
      "Train Epoch: 185 [10/50 (20%)]\tG_Loss: -0.392495 S_loss: 0.401420\n",
      "Train Epoch: 185 [20/50 (40%)]\tG_Loss: -0.393736 S_loss: 0.390069\n",
      "Train Epoch: 185 [30/50 (60%)]\tG_Loss: -0.407974 S_loss: 0.406319\n",
      "Train Epoch: 185 [40/50 (80%)]\tG_Loss: -0.422773 S_loss: 0.412822\n",
      "\n",
      "Test set: Average loss: 0.6147, Accuracy: 8561/10000 (85.6100%)\n",
      "\n",
      "Train Epoch: 186 [0/50 (0%)]\tG_Loss: -0.428278 S_loss: 0.392778\n",
      "Train Epoch: 186 [10/50 (20%)]\tG_Loss: -0.381375 S_loss: 0.403186\n",
      "Train Epoch: 186 [20/50 (40%)]\tG_Loss: -0.397654 S_loss: 0.403104\n",
      "Train Epoch: 186 [30/50 (60%)]\tG_Loss: -0.440089 S_loss: 0.394552\n",
      "Train Epoch: 186 [40/50 (80%)]\tG_Loss: -0.380730 S_loss: 0.393538\n",
      "\n",
      "Test set: Average loss: 0.6005, Accuracy: 8607/10000 (86.0700%)\n",
      "\n",
      "Train Epoch: 187 [0/50 (0%)]\tG_Loss: -0.398827 S_loss: 0.398861\n",
      "Train Epoch: 187 [10/50 (20%)]\tG_Loss: -0.445576 S_loss: 0.407091\n",
      "Train Epoch: 187 [20/50 (40%)]\tG_Loss: -0.396406 S_loss: 0.391675\n",
      "Train Epoch: 187 [30/50 (60%)]\tG_Loss: -0.407154 S_loss: 0.406313\n",
      "Train Epoch: 187 [40/50 (80%)]\tG_Loss: -0.412407 S_loss: 0.408961\n",
      "\n",
      "Test set: Average loss: 0.5891, Accuracy: 8649/10000 (86.4900%)\n",
      "\n",
      "Train Epoch: 188 [0/50 (0%)]\tG_Loss: -0.395431 S_loss: 0.393519\n",
      "Train Epoch: 188 [10/50 (20%)]\tG_Loss: -0.416015 S_loss: 0.399661\n",
      "Train Epoch: 188 [20/50 (40%)]\tG_Loss: -0.452905 S_loss: 0.384943\n",
      "Train Epoch: 188 [30/50 (60%)]\tG_Loss: -0.411983 S_loss: 0.400329\n",
      "Train Epoch: 188 [40/50 (80%)]\tG_Loss: -0.401986 S_loss: 0.397764\n",
      "\n",
      "Test set: Average loss: 0.6050, Accuracy: 8586/10000 (85.8600%)\n",
      "\n",
      "Train Epoch: 189 [0/50 (0%)]\tG_Loss: -0.399083 S_loss: 0.392213\n",
      "Train Epoch: 189 [10/50 (20%)]\tG_Loss: -0.417410 S_loss: 0.400351\n",
      "Train Epoch: 189 [20/50 (40%)]\tG_Loss: -0.423903 S_loss: 0.393614\n",
      "Train Epoch: 189 [30/50 (60%)]\tG_Loss: -0.455246 S_loss: 0.395566\n",
      "Train Epoch: 189 [40/50 (80%)]\tG_Loss: -0.421981 S_loss: 0.395680\n",
      "\n",
      "Test set: Average loss: 0.5802, Accuracy: 8644/10000 (86.4400%)\n",
      "\n",
      "Train Epoch: 190 [0/50 (0%)]\tG_Loss: -0.400745 S_loss: 0.387244\n",
      "Train Epoch: 190 [10/50 (20%)]\tG_Loss: -0.404150 S_loss: 0.388226\n",
      "Train Epoch: 190 [20/50 (40%)]\tG_Loss: -0.397760 S_loss: 0.395559\n",
      "Train Epoch: 190 [30/50 (60%)]\tG_Loss: -0.412893 S_loss: 0.402710\n",
      "Train Epoch: 190 [40/50 (80%)]\tG_Loss: -0.414716 S_loss: 0.402516\n",
      "\n",
      "Test set: Average loss: 0.5881, Accuracy: 8661/10000 (86.6100%)\n",
      "\n",
      "Train Epoch: 191 [0/50 (0%)]\tG_Loss: -0.418359 S_loss: 0.404070\n",
      "Train Epoch: 191 [10/50 (20%)]\tG_Loss: -0.416767 S_loss: 0.412137\n",
      "Train Epoch: 191 [20/50 (40%)]\tG_Loss: -0.407304 S_loss: 0.407463\n",
      "Train Epoch: 191 [30/50 (60%)]\tG_Loss: -0.402614 S_loss: 0.411236\n",
      "Train Epoch: 191 [40/50 (80%)]\tG_Loss: -0.448676 S_loss: 0.369928\n",
      "\n",
      "Test set: Average loss: 0.6018, Accuracy: 8622/10000 (86.2200%)\n",
      "\n",
      "Train Epoch: 192 [0/50 (0%)]\tG_Loss: -0.413894 S_loss: 0.398763\n",
      "Train Epoch: 192 [10/50 (20%)]\tG_Loss: -0.431720 S_loss: 0.410581\n",
      "Train Epoch: 192 [20/50 (40%)]\tG_Loss: -0.447671 S_loss: 0.402487\n",
      "Train Epoch: 192 [30/50 (60%)]\tG_Loss: -0.392968 S_loss: 0.394140\n",
      "Train Epoch: 192 [40/50 (80%)]\tG_Loss: -0.430573 S_loss: 0.404757\n",
      "\n",
      "Test set: Average loss: 0.5918, Accuracy: 8619/10000 (86.1900%)\n",
      "\n",
      "Train Epoch: 193 [0/50 (0%)]\tG_Loss: -0.408919 S_loss: 0.404580\n",
      "Train Epoch: 193 [10/50 (20%)]\tG_Loss: -0.444756 S_loss: 0.391532\n",
      "Train Epoch: 193 [20/50 (40%)]\tG_Loss: -0.397694 S_loss: 0.417034\n",
      "Train Epoch: 193 [30/50 (60%)]\tG_Loss: -0.394717 S_loss: 0.409125\n",
      "Train Epoch: 193 [40/50 (80%)]\tG_Loss: -0.433157 S_loss: 0.408482\n",
      "\n",
      "Test set: Average loss: 0.6048, Accuracy: 8600/10000 (86.0000%)\n",
      "\n",
      "Train Epoch: 194 [0/50 (0%)]\tG_Loss: -0.427998 S_loss: 0.410782\n",
      "Train Epoch: 194 [10/50 (20%)]\tG_Loss: -0.389439 S_loss: 0.386897\n",
      "Train Epoch: 194 [20/50 (40%)]\tG_Loss: -0.429383 S_loss: 0.401972\n",
      "Train Epoch: 194 [30/50 (60%)]\tG_Loss: -0.412513 S_loss: 0.398071\n",
      "Train Epoch: 194 [40/50 (80%)]\tG_Loss: -0.436972 S_loss: 0.419582\n",
      "\n",
      "Test set: Average loss: 0.5744, Accuracy: 8677/10000 (86.7700%)\n",
      "\n",
      "Train Epoch: 195 [0/50 (0%)]\tG_Loss: -0.407189 S_loss: 0.417124\n",
      "Train Epoch: 195 [10/50 (20%)]\tG_Loss: -0.403671 S_loss: 0.407020\n",
      "Train Epoch: 195 [20/50 (40%)]\tG_Loss: -0.403266 S_loss: 0.389102\n",
      "Train Epoch: 195 [30/50 (60%)]\tG_Loss: -0.417849 S_loss: 0.394936\n",
      "Train Epoch: 195 [40/50 (80%)]\tG_Loss: -0.410838 S_loss: 0.381530\n",
      "\n",
      "Test set: Average loss: 0.5711, Accuracy: 8677/10000 (86.7700%)\n",
      "\n",
      "Train Epoch: 196 [0/50 (0%)]\tG_Loss: -0.486705 S_loss: 0.403487\n",
      "Train Epoch: 196 [10/50 (20%)]\tG_Loss: -0.417503 S_loss: 0.399862\n",
      "Train Epoch: 196 [20/50 (40%)]\tG_Loss: -0.395464 S_loss: 0.401985\n",
      "Train Epoch: 196 [30/50 (60%)]\tG_Loss: -0.413943 S_loss: 0.403110\n",
      "Train Epoch: 196 [40/50 (80%)]\tG_Loss: -0.403580 S_loss: 0.422603\n",
      "\n",
      "Test set: Average loss: 0.6049, Accuracy: 8607/10000 (86.0700%)\n",
      "\n",
      "Train Epoch: 197 [0/50 (0%)]\tG_Loss: -0.403936 S_loss: 0.393504\n",
      "Train Epoch: 197 [10/50 (20%)]\tG_Loss: -0.429683 S_loss: 0.410634\n",
      "Train Epoch: 197 [20/50 (40%)]\tG_Loss: -0.419081 S_loss: 0.402886\n",
      "Train Epoch: 197 [30/50 (60%)]\tG_Loss: -0.418114 S_loss: 0.397524\n",
      "Train Epoch: 197 [40/50 (80%)]\tG_Loss: -0.431996 S_loss: 0.396750\n",
      "\n",
      "Test set: Average loss: 0.5823, Accuracy: 8657/10000 (86.5700%)\n",
      "\n",
      "Train Epoch: 198 [0/50 (0%)]\tG_Loss: -0.399695 S_loss: 0.388775\n",
      "Train Epoch: 198 [10/50 (20%)]\tG_Loss: -0.418731 S_loss: 0.398201\n",
      "Train Epoch: 198 [20/50 (40%)]\tG_Loss: -0.412734 S_loss: 0.378160\n",
      "Train Epoch: 198 [30/50 (60%)]\tG_Loss: -0.406699 S_loss: 0.418538\n",
      "Train Epoch: 198 [40/50 (80%)]\tG_Loss: -0.402457 S_loss: 0.383517\n",
      "\n",
      "Test set: Average loss: 0.5783, Accuracy: 8664/10000 (86.6400%)\n",
      "\n",
      "Train Epoch: 199 [0/50 (0%)]\tG_Loss: -0.395741 S_loss: 0.373300\n",
      "Train Epoch: 199 [10/50 (20%)]\tG_Loss: -0.386686 S_loss: 0.390393\n",
      "Train Epoch: 199 [20/50 (40%)]\tG_Loss: -0.429546 S_loss: 0.403537\n",
      "Train Epoch: 199 [30/50 (60%)]\tG_Loss: -0.417378 S_loss: 0.384667\n",
      "Train Epoch: 199 [40/50 (80%)]\tG_Loss: -0.412812 S_loss: 0.415136\n",
      "\n",
      "Test set: Average loss: 0.6097, Accuracy: 8604/10000 (86.0400%)\n",
      "\n",
      "Train Epoch: 200 [0/50 (0%)]\tG_Loss: -0.417918 S_loss: 0.407163\n",
      "Train Epoch: 200 [10/50 (20%)]\tG_Loss: -0.410980 S_loss: 0.390545\n",
      "Train Epoch: 200 [20/50 (40%)]\tG_Loss: -0.430202 S_loss: 0.393405\n",
      "Train Epoch: 200 [30/50 (60%)]\tG_Loss: -0.434790 S_loss: 0.404561\n",
      "Train Epoch: 200 [40/50 (80%)]\tG_Loss: -0.408574 S_loss: 0.393189\n",
      "\n",
      "Test set: Average loss: 0.5624, Accuracy: 8669/10000 (86.6900%)\n",
      "\n",
      "Train Epoch: 201 [0/50 (0%)]\tG_Loss: -0.388254 S_loss: 0.389108\n",
      "Train Epoch: 201 [10/50 (20%)]\tG_Loss: -0.392534 S_loss: 0.399905\n",
      "Train Epoch: 201 [20/50 (40%)]\tG_Loss: -0.454878 S_loss: 0.390325\n",
      "Train Epoch: 201 [30/50 (60%)]\tG_Loss: -0.454940 S_loss: 0.394007\n",
      "Train Epoch: 201 [40/50 (80%)]\tG_Loss: -0.404529 S_loss: 0.387967\n",
      "\n",
      "Test set: Average loss: 0.5756, Accuracy: 8673/10000 (86.7300%)\n",
      "\n",
      "Train Epoch: 202 [0/50 (0%)]\tG_Loss: -0.409060 S_loss: 0.384949\n",
      "Train Epoch: 202 [10/50 (20%)]\tG_Loss: -0.402692 S_loss: 0.385927\n",
      "Train Epoch: 202 [20/50 (40%)]\tG_Loss: -0.415009 S_loss: 0.385375\n",
      "Train Epoch: 202 [30/50 (60%)]\tG_Loss: -0.407596 S_loss: 0.392953\n",
      "Train Epoch: 202 [40/50 (80%)]\tG_Loss: -0.389928 S_loss: 0.397782\n",
      "\n",
      "Test set: Average loss: 0.5674, Accuracy: 8683/10000 (86.8300%)\n",
      "\n",
      "Train Epoch: 203 [0/50 (0%)]\tG_Loss: -0.391332 S_loss: 0.381721\n",
      "Train Epoch: 203 [10/50 (20%)]\tG_Loss: -0.390778 S_loss: 0.395857\n",
      "Train Epoch: 203 [20/50 (40%)]\tG_Loss: -0.405225 S_loss: 0.401643\n",
      "Train Epoch: 203 [30/50 (60%)]\tG_Loss: -0.419020 S_loss: 0.395815\n",
      "Train Epoch: 203 [40/50 (80%)]\tG_Loss: -0.401305 S_loss: 0.399141\n",
      "\n",
      "Test set: Average loss: 0.5781, Accuracy: 8660/10000 (86.6000%)\n",
      "\n",
      "Train Epoch: 204 [0/50 (0%)]\tG_Loss: -0.421358 S_loss: 0.389381\n",
      "Train Epoch: 204 [10/50 (20%)]\tG_Loss: -0.401647 S_loss: 0.380332\n",
      "Train Epoch: 204 [20/50 (40%)]\tG_Loss: -0.431245 S_loss: 0.405313\n",
      "Train Epoch: 204 [30/50 (60%)]\tG_Loss: -0.396877 S_loss: 0.403079\n",
      "Train Epoch: 204 [40/50 (80%)]\tG_Loss: -0.397763 S_loss: 0.386892\n",
      "\n",
      "Test set: Average loss: 0.5886, Accuracy: 8622/10000 (86.2200%)\n",
      "\n",
      "Train Epoch: 205 [0/50 (0%)]\tG_Loss: -0.425149 S_loss: 0.380490\n",
      "Train Epoch: 205 [10/50 (20%)]\tG_Loss: -0.440762 S_loss: 0.401147\n",
      "Train Epoch: 205 [20/50 (40%)]\tG_Loss: -0.411799 S_loss: 0.397887\n",
      "Train Epoch: 205 [30/50 (60%)]\tG_Loss: -0.398224 S_loss: 0.390365\n",
      "Train Epoch: 205 [40/50 (80%)]\tG_Loss: -0.426221 S_loss: 0.390103\n",
      "\n",
      "Test set: Average loss: 0.5516, Accuracy: 8704/10000 (87.0400%)\n",
      "\n",
      "Train Epoch: 206 [0/50 (0%)]\tG_Loss: -0.404325 S_loss: 0.384971\n",
      "Train Epoch: 206 [10/50 (20%)]\tG_Loss: -0.390335 S_loss: 0.381864\n",
      "Train Epoch: 206 [20/50 (40%)]\tG_Loss: -0.453634 S_loss: 0.404116\n",
      "Train Epoch: 206 [30/50 (60%)]\tG_Loss: -0.411178 S_loss: 0.397501\n",
      "Train Epoch: 206 [40/50 (80%)]\tG_Loss: -0.399193 S_loss: 0.389401\n",
      "\n",
      "Test set: Average loss: 0.5857, Accuracy: 8662/10000 (86.6200%)\n",
      "\n",
      "Train Epoch: 207 [0/50 (0%)]\tG_Loss: -0.387604 S_loss: 0.379493\n",
      "Train Epoch: 207 [10/50 (20%)]\tG_Loss: -0.410866 S_loss: 0.377139\n",
      "Train Epoch: 207 [20/50 (40%)]\tG_Loss: -0.401527 S_loss: 0.408170\n",
      "Train Epoch: 207 [30/50 (60%)]\tG_Loss: -0.400804 S_loss: 0.399237\n",
      "Train Epoch: 207 [40/50 (80%)]\tG_Loss: -0.437920 S_loss: 0.408150\n",
      "\n",
      "Test set: Average loss: 0.5874, Accuracy: 8628/10000 (86.2800%)\n",
      "\n",
      "Train Epoch: 208 [0/50 (0%)]\tG_Loss: -0.404811 S_loss: 0.383898\n",
      "Train Epoch: 208 [10/50 (20%)]\tG_Loss: -0.411552 S_loss: 0.400460\n",
      "Train Epoch: 208 [20/50 (40%)]\tG_Loss: -0.454648 S_loss: 0.417353\n",
      "Train Epoch: 208 [30/50 (60%)]\tG_Loss: -0.392293 S_loss: 0.385030\n",
      "Train Epoch: 208 [40/50 (80%)]\tG_Loss: -0.397706 S_loss: 0.384941\n",
      "\n",
      "Test set: Average loss: 0.5865, Accuracy: 8641/10000 (86.4100%)\n",
      "\n",
      "Train Epoch: 209 [0/50 (0%)]\tG_Loss: -0.435481 S_loss: 0.392607\n",
      "Train Epoch: 209 [10/50 (20%)]\tG_Loss: -0.399130 S_loss: 0.422660\n",
      "Train Epoch: 209 [20/50 (40%)]\tG_Loss: -0.422638 S_loss: 0.411509\n",
      "Train Epoch: 209 [30/50 (60%)]\tG_Loss: -0.411800 S_loss: 0.396563\n",
      "Train Epoch: 209 [40/50 (80%)]\tG_Loss: -0.402554 S_loss: 0.395279\n",
      "\n",
      "Test set: Average loss: 0.6299, Accuracy: 8513/10000 (85.1300%)\n",
      "\n",
      "Train Epoch: 210 [0/50 (0%)]\tG_Loss: -0.386599 S_loss: 0.393443\n",
      "Train Epoch: 210 [10/50 (20%)]\tG_Loss: -0.436193 S_loss: 0.385165\n",
      "Train Epoch: 210 [20/50 (40%)]\tG_Loss: -0.393855 S_loss: 0.386995\n",
      "Train Epoch: 210 [30/50 (60%)]\tG_Loss: -0.397769 S_loss: 0.412937\n",
      "Train Epoch: 210 [40/50 (80%)]\tG_Loss: -0.412663 S_loss: 0.388545\n",
      "\n",
      "Test set: Average loss: 0.5626, Accuracy: 8681/10000 (86.8100%)\n",
      "\n",
      "Train Epoch: 211 [0/50 (0%)]\tG_Loss: -0.388882 S_loss: 0.394356\n",
      "Train Epoch: 211 [10/50 (20%)]\tG_Loss: -0.417495 S_loss: 0.396535\n",
      "Train Epoch: 211 [20/50 (40%)]\tG_Loss: -0.420566 S_loss: 0.401177\n",
      "Train Epoch: 211 [30/50 (60%)]\tG_Loss: -0.407521 S_loss: 0.405293\n",
      "Train Epoch: 211 [40/50 (80%)]\tG_Loss: -0.403371 S_loss: 0.383995\n",
      "\n",
      "Test set: Average loss: 0.5575, Accuracy: 8700/10000 (87.0000%)\n",
      "\n",
      "Train Epoch: 212 [0/50 (0%)]\tG_Loss: -0.435013 S_loss: 0.397778\n",
      "Train Epoch: 212 [10/50 (20%)]\tG_Loss: -0.399065 S_loss: 0.383018\n",
      "Train Epoch: 212 [20/50 (40%)]\tG_Loss: -0.398682 S_loss: 0.385944\n",
      "Train Epoch: 212 [30/50 (60%)]\tG_Loss: -0.405164 S_loss: 0.389637\n",
      "Train Epoch: 212 [40/50 (80%)]\tG_Loss: -0.412108 S_loss: 0.401043\n",
      "\n",
      "Test set: Average loss: 0.5833, Accuracy: 8631/10000 (86.3100%)\n",
      "\n",
      "Train Epoch: 213 [0/50 (0%)]\tG_Loss: -0.417415 S_loss: 0.399428\n",
      "Train Epoch: 213 [10/50 (20%)]\tG_Loss: -0.424602 S_loss: 0.395300\n",
      "Train Epoch: 213 [20/50 (40%)]\tG_Loss: -0.402729 S_loss: 0.396875\n",
      "Train Epoch: 213 [30/50 (60%)]\tG_Loss: -0.404381 S_loss: 0.389989\n",
      "Train Epoch: 213 [40/50 (80%)]\tG_Loss: -0.410814 S_loss: 0.387250\n",
      "\n",
      "Test set: Average loss: 0.5847, Accuracy: 8635/10000 (86.3500%)\n",
      "\n",
      "Train Epoch: 214 [0/50 (0%)]\tG_Loss: -0.403116 S_loss: 0.409908\n",
      "Train Epoch: 214 [10/50 (20%)]\tG_Loss: -0.425822 S_loss: 0.406711\n",
      "Train Epoch: 214 [20/50 (40%)]\tG_Loss: -0.421936 S_loss: 0.396106\n",
      "Train Epoch: 214 [30/50 (60%)]\tG_Loss: -0.391311 S_loss: 0.404053\n",
      "Train Epoch: 214 [40/50 (80%)]\tG_Loss: -0.423724 S_loss: 0.402294\n",
      "\n",
      "Test set: Average loss: 0.5997, Accuracy: 8630/10000 (86.3000%)\n",
      "\n",
      "Train Epoch: 215 [0/50 (0%)]\tG_Loss: -0.418985 S_loss: 0.391027\n",
      "Train Epoch: 215 [10/50 (20%)]\tG_Loss: -0.414910 S_loss: 0.381992\n",
      "Train Epoch: 215 [20/50 (40%)]\tG_Loss: -0.405815 S_loss: 0.396864\n",
      "Train Epoch: 215 [30/50 (60%)]\tG_Loss: -0.425952 S_loss: 0.391929\n",
      "Train Epoch: 215 [40/50 (80%)]\tG_Loss: -0.404218 S_loss: 0.394042\n",
      "\n",
      "Test set: Average loss: 0.5638, Accuracy: 8712/10000 (87.1200%)\n",
      "\n",
      "Train Epoch: 216 [0/50 (0%)]\tG_Loss: -0.400843 S_loss: 0.386624\n",
      "Train Epoch: 216 [10/50 (20%)]\tG_Loss: -0.404640 S_loss: 0.386015\n",
      "Train Epoch: 216 [20/50 (40%)]\tG_Loss: -0.400105 S_loss: 0.380221\n",
      "Train Epoch: 216 [30/50 (60%)]\tG_Loss: -0.420370 S_loss: 0.395657\n",
      "Train Epoch: 216 [40/50 (80%)]\tG_Loss: -0.403123 S_loss: 0.411532\n",
      "\n",
      "Test set: Average loss: 0.5700, Accuracy: 8680/10000 (86.8000%)\n",
      "\n",
      "Train Epoch: 217 [0/50 (0%)]\tG_Loss: -0.439564 S_loss: 0.418048\n",
      "Train Epoch: 217 [10/50 (20%)]\tG_Loss: -0.428630 S_loss: 0.392126\n",
      "Train Epoch: 217 [20/50 (40%)]\tG_Loss: -0.388815 S_loss: 0.388717\n",
      "Train Epoch: 217 [30/50 (60%)]\tG_Loss: -0.379688 S_loss: 0.397199\n",
      "Train Epoch: 217 [40/50 (80%)]\tG_Loss: -0.411066 S_loss: 0.389596\n",
      "\n",
      "Test set: Average loss: 0.5914, Accuracy: 8632/10000 (86.3200%)\n",
      "\n",
      "Train Epoch: 218 [0/50 (0%)]\tG_Loss: -0.401999 S_loss: 0.394993\n",
      "Train Epoch: 218 [10/50 (20%)]\tG_Loss: -0.410754 S_loss: 0.394050\n",
      "Train Epoch: 218 [20/50 (40%)]\tG_Loss: -0.425060 S_loss: 0.387378\n",
      "Train Epoch: 218 [30/50 (60%)]\tG_Loss: -0.404968 S_loss: 0.391420\n",
      "Train Epoch: 218 [40/50 (80%)]\tG_Loss: -0.422159 S_loss: 0.385256\n",
      "\n",
      "Test set: Average loss: 0.5502, Accuracy: 8720/10000 (87.2000%)\n",
      "\n",
      "Train Epoch: 219 [0/50 (0%)]\tG_Loss: -0.410083 S_loss: 0.375930\n",
      "Train Epoch: 219 [10/50 (20%)]\tG_Loss: -0.409843 S_loss: 0.399348\n",
      "Train Epoch: 219 [20/50 (40%)]\tG_Loss: -0.389690 S_loss: 0.396133\n",
      "Train Epoch: 219 [30/50 (60%)]\tG_Loss: -0.413269 S_loss: 0.395438\n",
      "Train Epoch: 219 [40/50 (80%)]\tG_Loss: -0.405690 S_loss: 0.377423\n",
      "\n",
      "Test set: Average loss: 0.5360, Accuracy: 8727/10000 (87.2700%)\n",
      "\n",
      "Train Epoch: 220 [0/50 (0%)]\tG_Loss: -0.398574 S_loss: 0.387240\n",
      "Train Epoch: 220 [10/50 (20%)]\tG_Loss: -0.405806 S_loss: 0.402176\n",
      "Train Epoch: 220 [20/50 (40%)]\tG_Loss: -0.421829 S_loss: 0.387618\n",
      "Train Epoch: 220 [30/50 (60%)]\tG_Loss: -0.408835 S_loss: 0.381423\n",
      "Train Epoch: 220 [40/50 (80%)]\tG_Loss: -0.420521 S_loss: 0.396517\n",
      "\n",
      "Test set: Average loss: 0.5749, Accuracy: 8644/10000 (86.4400%)\n",
      "\n",
      "Train Epoch: 221 [0/50 (0%)]\tG_Loss: -0.408032 S_loss: 0.389967\n",
      "Train Epoch: 221 [10/50 (20%)]\tG_Loss: -0.405562 S_loss: 0.401404\n",
      "Train Epoch: 221 [20/50 (40%)]\tG_Loss: -0.419494 S_loss: 0.394815\n",
      "Train Epoch: 221 [30/50 (60%)]\tG_Loss: -0.413780 S_loss: 0.388350\n",
      "Train Epoch: 221 [40/50 (80%)]\tG_Loss: -0.416021 S_loss: 0.394348\n",
      "\n",
      "Test set: Average loss: 0.5499, Accuracy: 8744/10000 (87.4400%)\n",
      "\n",
      "Train Epoch: 222 [0/50 (0%)]\tG_Loss: -0.448072 S_loss: 0.386750\n",
      "Train Epoch: 222 [10/50 (20%)]\tG_Loss: -0.387064 S_loss: 0.390486\n",
      "Train Epoch: 222 [20/50 (40%)]\tG_Loss: -0.411337 S_loss: 0.380322\n",
      "Train Epoch: 222 [30/50 (60%)]\tG_Loss: -0.417111 S_loss: 0.369694\n",
      "Train Epoch: 222 [40/50 (80%)]\tG_Loss: -0.413416 S_loss: 0.403744\n",
      "\n",
      "Test set: Average loss: 0.5828, Accuracy: 8651/10000 (86.5100%)\n",
      "\n",
      "Train Epoch: 223 [0/50 (0%)]\tG_Loss: -0.409140 S_loss: 0.405061\n",
      "Train Epoch: 223 [10/50 (20%)]\tG_Loss: -0.411020 S_loss: 0.393572\n",
      "Train Epoch: 223 [20/50 (40%)]\tG_Loss: -0.393537 S_loss: 0.392724\n",
      "Train Epoch: 223 [30/50 (60%)]\tG_Loss: -0.418126 S_loss: 0.379500\n",
      "Train Epoch: 223 [40/50 (80%)]\tG_Loss: -0.395675 S_loss: 0.395723\n",
      "\n",
      "Test set: Average loss: 0.5350, Accuracy: 8746/10000 (87.4600%)\n",
      "\n",
      "Train Epoch: 224 [0/50 (0%)]\tG_Loss: -0.388212 S_loss: 0.387855\n",
      "\n",
      "Test set: Average loss: 0.5833, Accuracy: 8661/10000 (86.6100%)\n",
      "\n",
      "Best Acc=0.874600\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse, ipdb, json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"/kaggle/input/project/datafree/dfme\")\n",
    "import network\n",
    "# os.chdir(\"/kaggle/input/dfme13/\")\n",
    "from dataloader import get_dataloader\n",
    "from approximate_gradients import *\n",
    "from my_utils import *\n",
    "os.chdir(cwd)\n",
    "import os, random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import torchvision.models as models\n",
    "\n",
    "print(\"torch version\", torch.__version__)\n",
    "\n",
    "def myprint(a):\n",
    "    \"\"\"Log the print statements\"\"\"\n",
    "    global file\n",
    "    print(a); file.write(a); file.write(\"\\n\"); file.flush()\n",
    "\n",
    "\n",
    "def student_loss(args, s_logit, t_logit, return_t_logits=False):\n",
    "    \"\"\"Kl/ L1 Loss for student\"\"\"\n",
    "    print_logits =  False\n",
    "    if args.loss == \"l1\":\n",
    "        loss_fn = F.l1_loss\n",
    "        loss = loss_fn(s_logit, t_logit.detach())\n",
    "    elif args.loss == \"kl\":\n",
    "        loss_fn = F.kl_div\n",
    "        s_logit = F.log_softmax(s_logit, dim=1)\n",
    "        t_logit = F.softmax(t_logit, dim=1)\n",
    "        loss = loss_fn(s_logit, t_logit.detach(), reduction=\"batchmean\")\n",
    "    else:\n",
    "        raise ValueError(args.loss)\n",
    "\n",
    "    if return_t_logits:\n",
    "        return loss, t_logit.detach()\n",
    "    else:\n",
    "        return loss\n",
    "\n",
    "def generator_loss(args, s_logit, t_logit,  z = None, z_logit = None, reduction=\"mean\"):\n",
    "    assert 0 \n",
    "    \n",
    "    loss = - F.l1_loss( s_logit, t_logit , reduction=reduction) \n",
    "    \n",
    "            \n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(args, teacher, student, generator, device, optimizer, epoch):\n",
    "    \"\"\"Main Loop for one epoch of Training Generator and Student\"\"\"\n",
    "    global file\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "    \n",
    "    optimizer_S,  optimizer_G = optimizer\n",
    "\n",
    "    gradients = []\n",
    "    \n",
    "\n",
    "    for i in range(args.epoch_itrs):\n",
    "        \"\"\"Repeat epoch_itrs times per epoch\"\"\"\n",
    "        for _ in range(args.g_iter):\n",
    "            #Sample Random Noise\n",
    "            z = torch.randn((args.batch_size, args.nz)).to(device)\n",
    "            optimizer_G.zero_grad()\n",
    "            generator.train()\n",
    "            #Get fake image from generator\n",
    "            fake = generator(z, pre_x=args.approx_grad) # pre_x returns the output of G before applying the activation\n",
    "\n",
    "\n",
    "            ## APPOX GRADIENT\n",
    "            approx_grad_wrt_x, loss_G = estimate_gradient_objective(args, teacher, student, fake, \n",
    "                                                epsilon = args.grad_epsilon, m = args.grad_m, num_classes=args.num_classes, \n",
    "                                                device=device, pre_x=True)\n",
    "\n",
    "            fake.backward(approx_grad_wrt_x)\n",
    "                \n",
    "            optimizer_G.step()\n",
    "\n",
    "            if i == 0 and args.rec_grad_norm:\n",
    "                x_true_grad = measure_true_grad_norm(args, fake)\n",
    "\n",
    "        for _ in range(args.d_iter):\n",
    "            z = torch.randn((args.batch_size, args.nz)).to(device)\n",
    "            fake = generator(z).detach()\n",
    "            optimizer_S.zero_grad()\n",
    "\n",
    "            with torch.no_grad(): \n",
    "                t_logit = teacher(fake)\n",
    "\n",
    "            # Correction for the fake logits\n",
    "            if args.loss == \"l1\" and args.no_logits:\n",
    "                t_logit = F.log_softmax(t_logit, dim=1).detach()\n",
    "                if args.logit_correction == 'min':\n",
    "                    t_logit -= t_logit.min(dim=1).values.view(-1, 1).detach()\n",
    "                elif args.logit_correction == 'mean':\n",
    "                    t_logit -= t_logit.mean(dim=1).view(-1, 1).detach()\n",
    "\n",
    "\n",
    "            s_logit = student(fake)\n",
    "\n",
    "\n",
    "            loss_S = student_loss(args, s_logit, t_logit)\n",
    "            loss_S.backward()\n",
    "            optimizer_S.step()\n",
    "\n",
    "        # Log Results\n",
    "        if i % args.log_interval == 0:\n",
    "            myprint(f'Train Epoch: {epoch} [{i}/{args.epoch_itrs} ({100*float(i)/float(args.epoch_itrs):.0f}%)]\\tG_Loss: {loss_G.item():.6f} S_loss: {loss_S.item():.6f}')\n",
    "            \n",
    "            if i == 0:\n",
    "                with open(args.log_dir + \"/loss.csv\", \"a\") as f:\n",
    "                    f.write(\"%d,%f,%f\\n\"%(epoch, loss_G, loss_S))\n",
    "\n",
    "\n",
    "            if args.rec_grad_norm and i == 0:\n",
    "\n",
    "                G_grad_norm, S_grad_norm = compute_grad_norms(generator, student)\n",
    "                if i == 0:\n",
    "                    with open(args.log_dir + \"/norm_grad.csv\", \"a\") as f:\n",
    "                        f.write(\"%d,%f,%f,%f\\n\"%(epoch, G_grad_norm, S_grad_norm, x_true_grad))\n",
    "                    \n",
    "\n",
    "        # update query budget\n",
    "        args.query_budget -= args.cost_per_iteration\n",
    "\n",
    "        if args.query_budget < args.cost_per_iteration:\n",
    "            return \n",
    "\n",
    "\n",
    "def test(args, student = None, generator = None, device = \"cuda\", test_loader = None, epoch=0):\n",
    "    global file\n",
    "    student.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = student(data)\n",
    "\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    myprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    with open(args.log_dir + \"/accuracy.csv\", \"a\") as f:\n",
    "        f.write(\"%d,%f\\n\"%(epoch, accuracy))\n",
    "    acc = correct/len(test_loader.dataset)\n",
    "    return acc\n",
    "\n",
    "def compute_grad_norms(generator, student):\n",
    "    G_grad = []\n",
    "    for n, p in generator.named_parameters():\n",
    "        if \"weight\" in n:\n",
    "            # print('===========\\ngradient{}\\n----------\\n{}'.format(n, p.grad.norm().to(\"cpu\")))\n",
    "            G_grad.append(p.grad.norm().to(\"cpu\"))\n",
    "\n",
    "    S_grad = []\n",
    "    for n, p in student.named_parameters():\n",
    "        if \"weight\" in n:\n",
    "            # print('===========\\ngradient{}\\n----------\\n{}'.format(n, p.grad.norm().to(\"cpu\")))\n",
    "            S_grad.append(p.grad.norm().to(\"cpu\"))\n",
    "    return  np.mean(G_grad), np.mean(S_grad)\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='DFAD CIFAR')\n",
    "    parser.add_argument('--batch_size', type=int, default=256, metavar='N',help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--query_budget', type=float, default=20, metavar='N', help='Query budget for the extraction attack in millions (default: 20M)')\n",
    "    parser.add_argument('--epoch_itrs', type=int, default=50)  \n",
    "    parser.add_argument('--g_iter', type=int, default=1, help = \"Number of generator iterations per epoch_iter\")\n",
    "    parser.add_argument('--d_iter', type=int, default=5, help = \"Number of discriminator iterations per epoch_iter\")\n",
    "\n",
    "    parser.add_argument('--lr_S', type=float, default=0.1, metavar='LR', help='Student learning rate (default: 0.1)')\n",
    "    parser.add_argument('--lr_G', type=float, default=1e-4, help='Generator learning rate (default: 0.1)')\n",
    "    parser.add_argument('--nz', type=int, default=256, help = \"Size of random noise input to generator\")\n",
    "\n",
    "    parser.add_argument('--log_interval', type=int, default=10, metavar='N', help='how many batches to wait before logging training status')\n",
    "    \n",
    "    parser.add_argument('--loss', type=str, default='l1', choices=['l1', 'kl'],)\n",
    "    parser.add_argument('--scheduler', type=str, default='multistep', choices=['multistep', 'cosine', \"none\"],)\n",
    "    parser.add_argument('--steps', nargs='+', default = [0.1, 0.3, 0.5], type=float, help = \"Percentage epochs at which to take next step\")\n",
    "    parser.add_argument('--scale', type=float, default=3e-1, help = \"Fractional decrease in lr\")\n",
    "\n",
    "    parser.add_argument('--dataset', type=str, default='cifar10', choices=['svhn','cifar10'], help='dataset name (default: cifar10)')\n",
    "    parser.add_argument('--data_root', type=str, default='/kaggle/working/data')\n",
    "    parser.add_argument('--model', type=str, default='resnet34_8x', choices=classifiers, help='Target model name (default: resnet34_8x)')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-4)\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=random.randint(0, 100000), metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--ckpt', type=str, default='/kaggle/working/checkpoint/teacher/cifar10-resnet34_8x.pt')\n",
    "    \n",
    "\n",
    "    parser.add_argument('--student_load_path', type=str, default=None)\n",
    "    parser.add_argument('--model_id', type=str, default=\"debug\")\n",
    "\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--log_dir', type=str, default=\"/kaggle/working/save_results/cifar10\")\n",
    "\n",
    "    # Gradient approximation parameters\n",
    "    parser.add_argument('--approx_grad', type=int, default=1, help = 'Always set to 1')\n",
    "    parser.add_argument('--grad_m', type=int, default=1, help='Number of steps to approximate the gradients')\n",
    "    parser.add_argument('--grad_epsilon', type=float, default=1e-3) \n",
    "    \n",
    "\n",
    "    parser.add_argument('--forward_differences', type=int, default=1, help='Always set to 1')\n",
    "    \n",
    "\n",
    "    # Eigenvalues computation parameters\n",
    "    parser.add_argument('--no_logits', type=int, default=1)\n",
    "    parser.add_argument('--logit_correction', type=str, default='mean', choices=['none', 'mean'])\n",
    "\n",
    "    parser.add_argument('--rec_grad_norm', type=int, default=1)\n",
    "\n",
    "    parser.add_argument('--MAZE', type=int, default=0) \n",
    "\n",
    "    parser.add_argument('--store_checkpoints', type=int, default=1)\n",
    "\n",
    "    parser.add_argument('--student_model', type=str, default='resnet18_8x',\n",
    "                        help='Student model architecture (default: resnet18_8x)')\n",
    "\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "    args=parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "\n",
    "    args.query_budget *=  10**6\n",
    "    args.query_budget = int(args.query_budget)\n",
    "    if args.MAZE:\n",
    "\n",
    "        print(\"\\n\"*2)\n",
    "        print(\"#### /!\\ OVERWRITING ALL PARAMETERS FOR MAZE REPLCIATION ####\")\n",
    "        print(\"\\n\"*2)\n",
    "        args.scheduer = \"cosine\"\n",
    "        args.loss = \"kl\"\n",
    "        args.batch_size = 128\n",
    "        args.g_iter = 1\n",
    "        args.d_iter = 5\n",
    "        args.grad_m = 10\n",
    "        args.lr_G = 1e-4 \n",
    "        args.lr_S = 1e-1\n",
    "\n",
    "\n",
    "    if args.student_model not in classifiers:\n",
    "        if \"wrn\" not in args.student_model:\n",
    "            raise ValueError(\"Unknown model\")\n",
    "\n",
    "\n",
    "    pprint(args, width= 80)\n",
    "    print(args.log_dir)\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "\n",
    "    if args.store_checkpoints:\n",
    "        os.makedirs(args.log_dir + \"/checkpoint\", exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Save JSON with parameters\n",
    "    with open(args.log_dir + \"/parameters.json\", \"w\") as f:\n",
    "        json.dump(vars(args), f)\n",
    "\n",
    "    with open(args.log_dir + \"/loss.csv\", \"w\") as f:\n",
    "        f.write(\"epoch,loss_G,loss_S\\n\")\n",
    "\n",
    "    with open(args.log_dir + \"/accuracy.csv\", \"w\") as f:\n",
    "        f.write(\"epoch,accuracy\\n\")\n",
    "\n",
    "    if args.rec_grad_norm:\n",
    "        with open(args.log_dir + \"/norm_grad.csv\", \"w\") as f:\n",
    "            f.write(\"epoch,G_grad_norm,S_grad_norm,grad_wrt_X\\n\")\n",
    "\n",
    "    with open(\"/kaggle/working/latest_experiments.txt\", \"a\") as f:\n",
    "        f.write(args.log_dir + \"\\n\")\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    # Prepare the environment\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    device = torch.device(\"cuda:%d\"%args.device if use_cuda else \"cpu\")\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    \n",
    "    # Preparing checkpoints for the best Student\n",
    "    global file\n",
    "    model_dir = f\"/kaggle/working/checkpoint/student_{args.model_id}\"; args.model_dir = model_dir\n",
    "    if(not os.path.exists(model_dir)):\n",
    "        os.makedirs(model_dir)\n",
    "    with open(f\"{model_dir}/model_info.txt\", \"w\") as f:\n",
    "        json.dump(args.__dict__, f, indent=2)  \n",
    "    file = open(f\"{args.model_dir}/logs.txt\", \"w\") \n",
    "\n",
    "    print(args)\n",
    "\n",
    "    args.device = device\n",
    "\n",
    "    # Eigen values and vectors of the covariance matrix\n",
    "    _, test_loader = get_dataloader(args)\n",
    "\n",
    "\n",
    "    args.normalization_coefs = None\n",
    "    args.G_activation = torch.tanh\n",
    "\n",
    "    num_classes = 10 if args.dataset in ['cifar10', 'svhn'] else 100\n",
    "    args.num_classes = num_classes\n",
    "\n",
    "    if args.model == 'resnet34_8x':\n",
    "        teacher = network.resnet_8x.ResNet34_8x(num_classes=num_classes)\n",
    "        if args.dataset == 'svhn':\n",
    "            print(\"Loading SVHN TEACHER\")\n",
    "            args.ckpt = 'checkpoint/teacher/svhn-resnet34_8x.pt'\n",
    "        teacher.load_state_dict( torch.load( args.ckpt, map_location=device) )\n",
    "    else:\n",
    "        teacher = get_classifier(args.model, pretrained=True, num_classes=args.num_classes)\n",
    "    \n",
    "    \n",
    "\n",
    "    teacher.eval()\n",
    "    teacher = teacher.to(device)\n",
    "    myprint(\"Teacher restored from %s\"%(args.ckpt)) \n",
    "    print(f\"\\n\\t\\tTraining with {args.model} as a Target\\n\") \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = teacher(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTeacher - Test set: Accuracy: {}/{} ({:.4f}%)\\n'.format(correct, len(test_loader.dataset),accuracy))\n",
    "    \n",
    "    \n",
    "    \n",
    "    student = get_classifier(args.student_model, pretrained=False, num_classes=args.num_classes)\n",
    "    \n",
    "    generator = network.gan.GeneratorA(nz=args.nz, nc=3, img_size=32, activation=args.G_activation)\n",
    "\n",
    "\n",
    "    \n",
    "    student = student.to(device)\n",
    "    generator = generator.to(device)\n",
    "\n",
    "    args.generator = generator\n",
    "    args.student = student\n",
    "    args.teacher = teacher\n",
    "\n",
    "    \n",
    "    if args.student_load_path :\n",
    "        # \"checkpoint/student_no-grad/cifar10-resnet34_8x.pt\"\n",
    "        student.load_state_dict( torch.load( args.student_load_path ) )\n",
    "        myprint(\"Student initialized from %s\"%(args.student_load_path))\n",
    "        acc = test(args, student=student, generator=generator, device = device, test_loader = test_loader)\n",
    "\n",
    "    ## Compute the number of epochs with the given query budget:\n",
    "    args.cost_per_iteration = args.batch_size * (args.g_iter * (args.grad_m+1) + args.d_iter)\n",
    "\n",
    "    number_epochs = args.query_budget // (args.cost_per_iteration * args.epoch_itrs) + 1\n",
    "\n",
    "    print (f\"\\nTotal budget: {args.query_budget//1000}k\")\n",
    "    print (\"Cost per iterations: \", args.cost_per_iteration)\n",
    "    print (\"Total number of epochs: \", number_epochs)\n",
    "\n",
    "    optimizer_S = optim.SGD( student.parameters(), lr=args.lr_S, weight_decay=args.weight_decay, momentum=0.9 )\n",
    "\n",
    "    if args.MAZE:\n",
    "        optimizer_G = optim.SGD( generator.parameters(), lr=args.lr_G , weight_decay=args.weight_decay, momentum=0.9 )    \n",
    "    else:\n",
    "        optimizer_G = optim.Adam( generator.parameters(), lr=args.lr_G )\n",
    "    \n",
    "    steps = sorted([int(step * number_epochs) for step in args.steps])\n",
    "    print(\"Learning rate scheduling at steps: \", steps)\n",
    "    print()\n",
    "\n",
    "    if args.scheduler == \"multistep\":\n",
    "        scheduler_S = optim.lr_scheduler.MultiStepLR(optimizer_S, steps, args.scale)\n",
    "        scheduler_G = optim.lr_scheduler.MultiStepLR(optimizer_G, steps, args.scale)\n",
    "    elif args.scheduler == \"cosine\":\n",
    "        scheduler_S = optim.lr_scheduler.CosineAnnealingLR(optimizer_S, number_epochs)\n",
    "        scheduler_G = optim.lr_scheduler.CosineAnnealingLR(optimizer_G, number_epochs)\n",
    "\n",
    "\n",
    "    best_acc = 0\n",
    "    acc_list = []\n",
    "\n",
    "    for epoch in range(1, number_epochs + 1):\n",
    "        # Train\n",
    "        if args.scheduler != \"none\":\n",
    "            scheduler_S.step()\n",
    "            scheduler_G.step()\n",
    "        \n",
    "\n",
    "        train(args, teacher=teacher, student=student, generator=generator, device=device, optimizer=[optimizer_S, optimizer_G], epoch=epoch)\n",
    "        # Test\n",
    "        acc = test(args, student=student, generator=generator, device = device, test_loader = test_loader, epoch=epoch)\n",
    "        acc_list.append(acc)\n",
    "        if acc>best_acc:\n",
    "            best_acc = acc\n",
    "            name = 'resnet34_8x'\n",
    "            torch.save(student.state_dict(),f\"checkpoint/student_{args.model_id}/{args.dataset}-{name}.pt\")\n",
    "            torch.save(generator.state_dict(),f\"checkpoint/student_{args.model_id}/{args.dataset}-{name}-generator.pt\")\n",
    "        # vp.add_scalar('Acc', epoch, acc)\n",
    "        if args.store_checkpoints:\n",
    "            torch.save(student.state_dict(), args.log_dir + f\"/checkpoint/student.pt\")\n",
    "            torch.save(generator.state_dict(), args.log_dir + f\"/checkpoint/generator.pt\")\n",
    "    myprint(\"Best Acc=%.6f\"%best_acc)\n",
    "\n",
    "    with open(args.log_dir + \"/Max_accuracy = %f\"%best_acc, \"w\") as f:\n",
    "        f.write(\" \")\n",
    "\n",
    "     \n",
    "\n",
    "    import csv\n",
    "    os.makedirs('log', exist_ok=True)\n",
    "    with open('log/DFAD-%s.csv'%(args.dataset), 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(acc_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21869.529331,
   "end_time": "2022-04-20T11:39:19.857769",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-20T05:34:50.328438",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0be6382ef23c4fba829fc38b520d6100": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_51c94014154e4e2d816e394c9744c1a1",
       "placeholder": "​",
       "style": "IPY_MODEL_512c66c50f7f48fb8d6148d3e2087d82",
       "value": ""
      }
     },
     "3c64294ba8824f03b6fe96ef0b601493": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "512c66c50f7f48fb8d6148d3e2087d82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "51c94014154e4e2d816e394c9744c1a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ed91dfd548246eb8e6a889be144f2fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "60db0a2f6a4a41c8a2052391f99dd810": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89523204f5cd40e08d7868ff113e1e2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b743b0abeb5e4a8bb7ff6987a19cc397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_60db0a2f6a4a41c8a2052391f99dd810",
       "placeholder": "​",
       "style": "IPY_MODEL_5ed91dfd548246eb8e6a889be144f2fb",
       "value": " 170499072/? [00:05&lt;00:00, 32203546.93it/s]"
      }
     },
     "c793af3c27ad487d89a39789866c5ea4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0be6382ef23c4fba829fc38b520d6100",
        "IPY_MODEL_e9f3ef41aa104056b87501f506fd8749",
        "IPY_MODEL_b743b0abeb5e4a8bb7ff6987a19cc397"
       ],
       "layout": "IPY_MODEL_89523204f5cd40e08d7868ff113e1e2a"
      }
     },
     "e9f3ef41aa104056b87501f506fd8749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc00b0a0f18140d7a4f2457365057bd0",
       "max": 170498071.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3c64294ba8824f03b6fe96ef0b601493",
       "value": 170498071.0
      }
     },
     "fc00b0a0f18140d7a4f2457365057bd0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
